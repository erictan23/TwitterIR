{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "import re\n",
    "import nltk\n",
    "from wordcloud import WordCloud\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import time \n",
    "import contractions\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from textblob import TextBlob\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing  import LabelEncoder\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing of Kaggle Repository Twitter Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Classification Task, we are trying to train a model to classify our crawled dataset whether the tweets are subjective or objective, positive or negative sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(\"textblob_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 88045 entries, 0 to 88044\n",
      "Data columns (total 12 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Unnamed: 0             88045 non-null  int64  \n",
      " 1   tweet_id               88045 non-null  float64\n",
      " 2   ticker_symbol          88045 non-null  object \n",
      " 3   writer                 88045 non-null  object \n",
      " 4   post_date              88045 non-null  object \n",
      " 5   body                   88045 non-null  object \n",
      " 6   comment_num            88045 non-null  int64  \n",
      " 7   retweet_num            88045 non-null  int64  \n",
      " 8   like_num               88045 non-null  int64  \n",
      " 9   tweet_activity         88045 non-null  int64  \n",
      " 10  sentiment_category     88045 non-null  int64  \n",
      " 11  subjectivity_category  88045 non-null  int64  \n",
      "dtypes: float64(1), int64(7), object(4)\n",
      "memory usage: 8.1+ MB\n"
     ]
    }
   ],
   "source": [
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>writer</th>\n",
       "      <th>post_date</th>\n",
       "      <th>body</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "      <th>tweet_activity</th>\n",
       "      <th>sentiment_category</th>\n",
       "      <th>subjectivity_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3786974</td>\n",
       "      <td>1.010000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>lopezlinette</td>\n",
       "      <td>5/7/2018</td>\n",
       "      <td>I’d just like to point out that right now, rig...</td>\n",
       "      <td>631</td>\n",
       "      <td>369</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4112626</td>\n",
       "      <td>1.120000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>GerberKawasaki</td>\n",
       "      <td>18/4/2019</td>\n",
       "      <td>If a Tesla saves you $200 a month on gas, you ...</td>\n",
       "      <td>567</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>567</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4306536</td>\n",
       "      <td>1.200000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>AlexSibila</td>\n",
       "      <td>26/11/2019</td>\n",
       "      <td>~Tesla feature request thread~Feel free to rep...</td>\n",
       "      <td>563</td>\n",
       "      <td>48</td>\n",
       "      <td>662</td>\n",
       "      <td>1273</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2823018</td>\n",
       "      <td>8.860000e+17</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>internet_dust</td>\n",
       "      <td>14/7/2017</td>\n",
       "      <td>\"I sell books.\" versus \"I sell whatever the fu...</td>\n",
       "      <td>496</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>496</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4182686</td>\n",
       "      <td>1.140000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>TeslaNY</td>\n",
       "      <td>13/6/2019</td>\n",
       "      <td>“I think it's basically financially insane to ...</td>\n",
       "      <td>442</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>442</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      tweet_id ticker_symbol          writer   post_date  \\\n",
       "0     3786974  1.010000e+18          TSLA    lopezlinette    5/7/2018   \n",
       "1     4112626  1.120000e+18          TSLA  GerberKawasaki   18/4/2019   \n",
       "2     4306536  1.200000e+18          TSLA      AlexSibila  26/11/2019   \n",
       "3     2823018  8.860000e+17          AMZN   internet_dust   14/7/2017   \n",
       "4     4182686  1.140000e+18          TSLA         TeslaNY   13/6/2019   \n",
       "\n",
       "                                                body  comment_num  \\\n",
       "0  I’d just like to point out that right now, rig...          631   \n",
       "1  If a Tesla saves you $200 a month on gas, you ...          567   \n",
       "2  ~Tesla feature request thread~Feel free to rep...          563   \n",
       "3  \"I sell books.\" versus \"I sell whatever the fu...          496   \n",
       "4  “I think it's basically financially insane to ...          442   \n",
       "\n",
       "   retweet_num  like_num  tweet_activity  sentiment_category  \\\n",
       "0          369         0            1000                   1   \n",
       "1            0         0             567                   1   \n",
       "2           48       662            1273                   1   \n",
       "3            0         0             496                  -1   \n",
       "4            0         0             442                  -1   \n",
       "\n",
       "   subjectivity_category  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      1  \n",
       "3                      1  \n",
       "4                      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>writer</th>\n",
       "      <th>post_date</th>\n",
       "      <th>body</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "      <th>tweet_activity</th>\n",
       "      <th>sentiment_category</th>\n",
       "      <th>subjectivity_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3786974</td>\n",
       "      <td>1.010000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>lopezlinette</td>\n",
       "      <td>5/7/2018</td>\n",
       "      <td>I’d just like to point out that right now, rig...</td>\n",
       "      <td>631</td>\n",
       "      <td>369</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4112626</td>\n",
       "      <td>1.120000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>GerberKawasaki</td>\n",
       "      <td>18/4/2019</td>\n",
       "      <td>If a Tesla saves you $200 a month on gas, you ...</td>\n",
       "      <td>567</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>567</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4306536</td>\n",
       "      <td>1.200000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>AlexSibila</td>\n",
       "      <td>26/11/2019</td>\n",
       "      <td>~Tesla feature request thread~Feel free to rep...</td>\n",
       "      <td>563</td>\n",
       "      <td>48</td>\n",
       "      <td>662</td>\n",
       "      <td>1273</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2823018</td>\n",
       "      <td>8.860000e+17</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>internet_dust</td>\n",
       "      <td>14/7/2017</td>\n",
       "      <td>\"I sell books.\" versus \"I sell whatever the fu...</td>\n",
       "      <td>496</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>496</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4182686</td>\n",
       "      <td>1.140000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>TeslaNY</td>\n",
       "      <td>13/6/2019</td>\n",
       "      <td>“I think it's basically financially insane to ...</td>\n",
       "      <td>442</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>442</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      tweet_id ticker_symbol          writer   post_date  \\\n",
       "0     3786974  1.010000e+18          TSLA    lopezlinette    5/7/2018   \n",
       "1     4112626  1.120000e+18          TSLA  GerberKawasaki   18/4/2019   \n",
       "2     4306536  1.200000e+18          TSLA      AlexSibila  26/11/2019   \n",
       "3     2823018  8.860000e+17          AMZN   internet_dust   14/7/2017   \n",
       "4     4182686  1.140000e+18          TSLA         TeslaNY   13/6/2019   \n",
       "\n",
       "                                                body  comment_num  \\\n",
       "0  I’d just like to point out that right now, rig...          631   \n",
       "1  If a Tesla saves you $200 a month on gas, you ...          567   \n",
       "2  ~Tesla feature request thread~Feel free to rep...          563   \n",
       "3  \"I sell books.\" versus \"I sell whatever the fu...          496   \n",
       "4  “I think it's basically financially insane to ...          442   \n",
       "\n",
       "   retweet_num  like_num  tweet_activity  sentiment_category  \\\n",
       "0          369         0            1000                   1   \n",
       "1            0         0             567                   1   \n",
       "2           48       662            1273                   1   \n",
       "3            0         0             496                  -1   \n",
       "4            0         0             442                  -1   \n",
       "\n",
       "   subjectivity_category  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      1  \n",
       "3                      1  \n",
       "4                      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing of Crawled Twitter Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the crawled dataset from twitter with regards to stocks such as AAPL, AMZN, MSFT, TSLA, GOOGL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawled_tweets = pd.read_csv('new_label_acc_100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>post_date</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>writer</th>\n",
       "      <th>body</th>\n",
       "      <th>like_num</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>tweet_activity</th>\n",
       "      <th>url_cnt</th>\n",
       "      <th>...</th>\n",
       "      <th>word_count</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>subjectivity_1</th>\n",
       "      <th>sentiment_1</th>\n",
       "      <th>subjectivity_2</th>\n",
       "      <th>sentiment_2</th>\n",
       "      <th>moderator_sub</th>\n",
       "      <th>moderator_sen</th>\n",
       "      <th>vote_subjectivity</th>\n",
       "      <th>vote_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4293</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2023-02-28 23:25:43+00:00</td>\n",
       "      <td>1.630711e+18</td>\n",
       "      <td>BestTrader01</td>\n",
       "      <td>$TSLA #TSLA Options Interest! $800sssss, 600ss...</td>\n",
       "      <td>59</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>tsla tsla option interest 800sssss 600sss 300s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4294</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2023-02-28 23:23:40+00:00</td>\n",
       "      <td>1.630710e+18</td>\n",
       "      <td>MatchasmMatt</td>\n",
       "      <td>$RIVN down nearly 10% after earnings. These co...</td>\n",
       "      <td>84</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>rivn nearli 10 earn compani make tsla look goo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4295</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2023-02-28 23:20:10+00:00</td>\n",
       "      <td>1.630709e+18</td>\n",
       "      <td>susanblas</td>\n",
       "      <td>No surprise here. $TSLA does not give a flying...</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>surpris tsla give fli fuck custom theyv taken</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4296</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2023-02-28 23:12:27+00:00</td>\n",
       "      <td>1.630708e+18</td>\n",
       "      <td>stevenmarkryan</td>\n",
       "      <td>Is it just me or is it CREEPY AF that I get no...</td>\n",
       "      <td>267</td>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>311</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>creepi af get notif someon add list includ ad ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4297</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2023-02-28 23:06:48+00:00</td>\n",
       "      <td>1.630706e+18</td>\n",
       "      <td>stevenmarkryan</td>\n",
       "      <td>Can't wait to see how pissed the cry babies wh...</td>\n",
       "      <td>289</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>cant wait see piss cri babi also tsla elonmusk...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ticker_symbol                  post_date      tweet_id          writer  \\\n",
       "4293          TSLA  2023-02-28 23:25:43+00:00  1.630711e+18    BestTrader01   \n",
       "4294          TSLA  2023-02-28 23:23:40+00:00  1.630710e+18    MatchasmMatt   \n",
       "4295          TSLA  2023-02-28 23:20:10+00:00  1.630709e+18       susanblas   \n",
       "4296          TSLA  2023-02-28 23:12:27+00:00  1.630708e+18  stevenmarkryan   \n",
       "4297          TSLA  2023-02-28 23:06:48+00:00  1.630706e+18  stevenmarkryan   \n",
       "\n",
       "                                                   body  like_num  \\\n",
       "4293  $TSLA #TSLA Options Interest! $800sssss, 600ss...        59   \n",
       "4294  $RIVN down nearly 10% after earnings. These co...        84   \n",
       "4295  No surprise here. $TSLA does not give a flying...        39   \n",
       "4296  Is it just me or is it CREEPY AF that I get no...       267   \n",
       "4297  Can't wait to see how pissed the cry babies wh...       289   \n",
       "\n",
       "      comment_num  retweet_num  tweet_activity  url_cnt  ... word_count  \\\n",
       "4293            7            5              71        1  ...         10   \n",
       "4294           10            2              96        0  ...         10   \n",
       "4295            0           11              50        0  ...          8   \n",
       "4296           37            7             311        0  ...         23   \n",
       "4297           16           15             320        0  ...         31   \n",
       "\n",
       "                                             clean_text  subjectivity_1  \\\n",
       "4293  tsla tsla option interest 800sssss 600sss 300s...               0   \n",
       "4294  rivn nearli 10 earn compani make tsla look goo...               1   \n",
       "4295      surpris tsla give fli fuck custom theyv taken               1   \n",
       "4296  creepi af get notif someon add list includ ad ...               1   \n",
       "4297  cant wait see piss cri babi also tsla elonmusk...               1   \n",
       "\n",
       "      sentiment_1 subjectivity_2  sentiment_2  moderator_sub  moderator_sen  \\\n",
       "4293            0              0            0            NaN            NaN   \n",
       "4294            1              1            1            NaN            NaN   \n",
       "4295           -1              1           -1            NaN            NaN   \n",
       "4296            1              0            0            0.0            0.0   \n",
       "4297           -1              1           -1            NaN            NaN   \n",
       "\n",
       "      vote_subjectivity  vote_sentiment  \n",
       "4293                0.0             0.0  \n",
       "4294                1.0             1.0  \n",
       "4295                1.0            -1.0  \n",
       "4296                0.0             0.0  \n",
       "4297                1.0            -1.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crawled_tweets.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawled_tweets['vote_subjectivity'] = crawled_tweets['vote_subjectivity'].astype(int)\n",
    "crawled_tweets['vote_sentiment']= crawled_tweets['vote_sentiment'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>post_date</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>writer</th>\n",
       "      <th>body</th>\n",
       "      <th>like_num</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>tweet_activity</th>\n",
       "      <th>url_cnt</th>\n",
       "      <th>...</th>\n",
       "      <th>word_count</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>subjectivity_1</th>\n",
       "      <th>sentiment_1</th>\n",
       "      <th>subjectivity_2</th>\n",
       "      <th>sentiment_2</th>\n",
       "      <th>moderator_sub</th>\n",
       "      <th>moderator_sen</th>\n",
       "      <th>vote_subjectivity</th>\n",
       "      <th>vote_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2023-01-01 22:23:31+00:00</td>\n",
       "      <td>1.609677e+18</td>\n",
       "      <td>David_Tracey</td>\n",
       "      <td>Things are going to get very interesting but w...</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>thing go get interest q1 forecast updat aapl r...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2023-01-01 21:04:45+00:00</td>\n",
       "      <td>1.609657e+18</td>\n",
       "      <td>ASTS_Investors</td>\n",
       "      <td>Happy New Year SpaceMob! \\n\\nLet's hope 2023 w...</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>happi new year spacemob let hope 2023 year blu...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2023-01-01 20:44:51+00:00</td>\n",
       "      <td>1.609652e+18</td>\n",
       "      <td>BigCheds</td>\n",
       "      <td>$AAPL Apple weekly chart - hammer candle with ...</td>\n",
       "      <td>104</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>aapl appl weekli chart hammer candl spring jun...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2023-01-01 19:45:30+00:00</td>\n",
       "      <td>1.609637e+18</td>\n",
       "      <td>ThetaWarrior</td>\n",
       "      <td>$AAPL Yearly -26.8% https://t.co/SewErQmOPE</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>aapl yearli 268 urlplacehold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2023-01-01 19:00:00+00:00</td>\n",
       "      <td>1.609626e+18</td>\n",
       "      <td>TrendSpider</td>\n",
       "      <td>Looking for shorts into the new year? 📉\\n\\nThi...</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>look short new year emojiplacehold weekli tria...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4293</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2023-02-28 23:25:43+00:00</td>\n",
       "      <td>1.630711e+18</td>\n",
       "      <td>BestTrader01</td>\n",
       "      <td>$TSLA #TSLA Options Interest! $800sssss, 600ss...</td>\n",
       "      <td>59</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>tsla tsla option interest 800sssss 600sss 300s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4294</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2023-02-28 23:23:40+00:00</td>\n",
       "      <td>1.630710e+18</td>\n",
       "      <td>MatchasmMatt</td>\n",
       "      <td>$RIVN down nearly 10% after earnings. These co...</td>\n",
       "      <td>84</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>rivn nearli 10 earn compani make tsla look goo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4295</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2023-02-28 23:20:10+00:00</td>\n",
       "      <td>1.630709e+18</td>\n",
       "      <td>susanblas</td>\n",
       "      <td>No surprise here. $TSLA does not give a flying...</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>surpris tsla give fli fuck custom theyv taken</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4296</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2023-02-28 23:12:27+00:00</td>\n",
       "      <td>1.630708e+18</td>\n",
       "      <td>stevenmarkryan</td>\n",
       "      <td>Is it just me or is it CREEPY AF that I get no...</td>\n",
       "      <td>267</td>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>311</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>creepi af get notif someon add list includ ad ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4297</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2023-02-28 23:06:48+00:00</td>\n",
       "      <td>1.630706e+18</td>\n",
       "      <td>stevenmarkryan</td>\n",
       "      <td>Can't wait to see how pissed the cry babies wh...</td>\n",
       "      <td>289</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>cant wait see piss cri babi also tsla elonmusk...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4298 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ticker_symbol                  post_date      tweet_id          writer  \\\n",
       "0             AAPL  2023-01-01 22:23:31+00:00  1.609677e+18    David_Tracey   \n",
       "1             AAPL  2023-01-01 21:04:45+00:00  1.609657e+18  ASTS_Investors   \n",
       "2             AAPL  2023-01-01 20:44:51+00:00  1.609652e+18        BigCheds   \n",
       "3             AAPL  2023-01-01 19:45:30+00:00  1.609637e+18    ThetaWarrior   \n",
       "4             AAPL  2023-01-01 19:00:00+00:00  1.609626e+18     TrendSpider   \n",
       "...            ...                        ...           ...             ...   \n",
       "4293          TSLA  2023-02-28 23:25:43+00:00  1.630711e+18    BestTrader01   \n",
       "4294          TSLA  2023-02-28 23:23:40+00:00  1.630710e+18    MatchasmMatt   \n",
       "4295          TSLA  2023-02-28 23:20:10+00:00  1.630709e+18       susanblas   \n",
       "4296          TSLA  2023-02-28 23:12:27+00:00  1.630708e+18  stevenmarkryan   \n",
       "4297          TSLA  2023-02-28 23:06:48+00:00  1.630706e+18  stevenmarkryan   \n",
       "\n",
       "                                                   body  like_num  \\\n",
       "0     Things are going to get very interesting but w...        27   \n",
       "1     Happy New Year SpaceMob! \\n\\nLet's hope 2023 w...        64   \n",
       "2     $AAPL Apple weekly chart - hammer candle with ...       104   \n",
       "3           $AAPL Yearly -26.8% https://t.co/SewErQmOPE        80   \n",
       "4     Looking for shorts into the new year? 📉\\n\\nThi...        28   \n",
       "...                                                 ...       ...   \n",
       "4293  $TSLA #TSLA Options Interest! $800sssss, 600ss...        59   \n",
       "4294  $RIVN down nearly 10% after earnings. These co...        84   \n",
       "4295  No surprise here. $TSLA does not give a flying...        39   \n",
       "4296  Is it just me or is it CREEPY AF that I get no...       267   \n",
       "4297  Can't wait to see how pissed the cry babies wh...       289   \n",
       "\n",
       "      comment_num  retweet_num  tweet_activity  url_cnt  ... word_count  \\\n",
       "0               1            2              30        2  ...         11   \n",
       "1               0            3              67        1  ...         21   \n",
       "2               9            5             118        1  ...         10   \n",
       "3              10           10             100        1  ...          4   \n",
       "4               4            4              36        1  ...         23   \n",
       "...           ...          ...             ...      ...  ...        ...   \n",
       "4293            7            5              71        1  ...         10   \n",
       "4294           10            2              96        0  ...         10   \n",
       "4295            0           11              50        0  ...          8   \n",
       "4296           37            7             311        0  ...         23   \n",
       "4297           16           15             320        0  ...         31   \n",
       "\n",
       "                                             clean_text  subjectivity_1  \\\n",
       "0     thing go get interest q1 forecast updat aapl r...               0   \n",
       "1     happi new year spacemob let hope 2023 year blu...               0   \n",
       "2     aapl appl weekli chart hammer candl spring jun...               0   \n",
       "3                          aapl yearli 268 urlplacehold               0   \n",
       "4     look short new year emojiplacehold weekli tria...               0   \n",
       "...                                                 ...             ...   \n",
       "4293  tsla tsla option interest 800sssss 600sss 300s...               0   \n",
       "4294  rivn nearli 10 earn compani make tsla look goo...               1   \n",
       "4295      surpris tsla give fli fuck custom theyv taken               1   \n",
       "4296  creepi af get notif someon add list includ ad ...               1   \n",
       "4297  cant wait see piss cri babi also tsla elonmusk...               1   \n",
       "\n",
       "      sentiment_1 subjectivity_2  sentiment_2  moderator_sub  moderator_sen  \\\n",
       "0               0              0            0            NaN            NaN   \n",
       "1               1              0            1            NaN            NaN   \n",
       "2               0              0            0            NaN            NaN   \n",
       "3               0              0            0            NaN            NaN   \n",
       "4               1              0            1            NaN            NaN   \n",
       "...           ...            ...          ...            ...            ...   \n",
       "4293            0              0            0            NaN            NaN   \n",
       "4294            1              1            1            NaN            NaN   \n",
       "4295           -1              1           -1            NaN            NaN   \n",
       "4296            1              0            0            0.0            0.0   \n",
       "4297           -1              1           -1            NaN            NaN   \n",
       "\n",
       "      vote_subjectivity  vote_sentiment  \n",
       "0                     0               0  \n",
       "1                     0               1  \n",
       "2                     0               0  \n",
       "3                     0               0  \n",
       "4                     0               1  \n",
       "...                 ...             ...  \n",
       "4293                  0               0  \n",
       "4294                  1               1  \n",
       "4295                  1              -1  \n",
       "4296                  0               0  \n",
       "4297                  1              -1  \n",
       "\n",
       "[4298 rows x 23 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crawled_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>post_date</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>writer</th>\n",
       "      <th>body</th>\n",
       "      <th>like_num</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>tweet_activity</th>\n",
       "      <th>url_cnt</th>\n",
       "      <th>...</th>\n",
       "      <th>word_count</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>subjectivity_1</th>\n",
       "      <th>sentiment_1</th>\n",
       "      <th>subjectivity_2</th>\n",
       "      <th>sentiment_2</th>\n",
       "      <th>moderator_sub</th>\n",
       "      <th>moderator_sen</th>\n",
       "      <th>vote_subjectivity</th>\n",
       "      <th>vote_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2023-01-01 22:23:31+00:00</td>\n",
       "      <td>1.609677e+18</td>\n",
       "      <td>David_Tracey</td>\n",
       "      <td>Things are going to get very interesting but w...</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>thing go get interest q1 forecast updat aapl r...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2023-01-01 21:04:45+00:00</td>\n",
       "      <td>1.609657e+18</td>\n",
       "      <td>ASTS_Investors</td>\n",
       "      <td>Happy New Year SpaceMob! \\n\\nLet's hope 2023 w...</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>happi new year spacemob let hope 2023 year blu...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2023-01-01 20:44:51+00:00</td>\n",
       "      <td>1.609652e+18</td>\n",
       "      <td>BigCheds</td>\n",
       "      <td>$AAPL Apple weekly chart - hammer candle with ...</td>\n",
       "      <td>104</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>aapl appl weekli chart hammer candl spring jun...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2023-01-01 19:45:30+00:00</td>\n",
       "      <td>1.609637e+18</td>\n",
       "      <td>ThetaWarrior</td>\n",
       "      <td>$AAPL Yearly -26.8% https://t.co/SewErQmOPE</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>aapl yearli 268 urlplacehold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2023-01-01 19:00:00+00:00</td>\n",
       "      <td>1.609626e+18</td>\n",
       "      <td>TrendSpider</td>\n",
       "      <td>Looking for shorts into the new year? 📉\\n\\nThi...</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>look short new year emojiplacehold weekli tria...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker_symbol                  post_date      tweet_id          writer  \\\n",
       "0          AAPL  2023-01-01 22:23:31+00:00  1.609677e+18    David_Tracey   \n",
       "1          AAPL  2023-01-01 21:04:45+00:00  1.609657e+18  ASTS_Investors   \n",
       "2          AAPL  2023-01-01 20:44:51+00:00  1.609652e+18        BigCheds   \n",
       "3          AAPL  2023-01-01 19:45:30+00:00  1.609637e+18    ThetaWarrior   \n",
       "4          AAPL  2023-01-01 19:00:00+00:00  1.609626e+18     TrendSpider   \n",
       "\n",
       "                                                body  like_num  comment_num  \\\n",
       "0  Things are going to get very interesting but w...        27            1   \n",
       "1  Happy New Year SpaceMob! \\n\\nLet's hope 2023 w...        64            0   \n",
       "2  $AAPL Apple weekly chart - hammer candle with ...       104            9   \n",
       "3        $AAPL Yearly -26.8% https://t.co/SewErQmOPE        80           10   \n",
       "4  Looking for shorts into the new year? 📉\\n\\nThi...        28            4   \n",
       "\n",
       "   retweet_num  tweet_activity  url_cnt  ... word_count  \\\n",
       "0            2              30        2  ...         11   \n",
       "1            3              67        1  ...         21   \n",
       "2            5             118        1  ...         10   \n",
       "3           10             100        1  ...          4   \n",
       "4            4              36        1  ...         23   \n",
       "\n",
       "                                          clean_text  subjectivity_1  \\\n",
       "0  thing go get interest q1 forecast updat aapl r...               0   \n",
       "1  happi new year spacemob let hope 2023 year blu...               0   \n",
       "2  aapl appl weekli chart hammer candl spring jun...               0   \n",
       "3                       aapl yearli 268 urlplacehold               0   \n",
       "4  look short new year emojiplacehold weekli tria...               0   \n",
       "\n",
       "   sentiment_1 subjectivity_2  sentiment_2  moderator_sub  moderator_sen  \\\n",
       "0            0              0            0            NaN            NaN   \n",
       "1            1              0            1            NaN            NaN   \n",
       "2            0              0            0            NaN            NaN   \n",
       "3            0              0            0            NaN            NaN   \n",
       "4            1              0            1            NaN            NaN   \n",
       "\n",
       "   vote_subjectivity  vote_sentiment  \n",
       "0                  0               0  \n",
       "1                  0               1  \n",
       "2                  0               0  \n",
       "3                  0               0  \n",
       "4                  0               1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crawled_tweets.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After Merging Remove the dataframes that columns are empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.dropna(inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refactoring the Polarity Values of testing crawled_tweets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert our tweet date_time into just date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>writer</th>\n",
       "      <th>post_date</th>\n",
       "      <th>body</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "      <th>tweet_activity</th>\n",
       "      <th>sentiment_category</th>\n",
       "      <th>subjectivity_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3786974</td>\n",
       "      <td>1.010000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>lopezlinette</td>\n",
       "      <td>5/7/2018</td>\n",
       "      <td>I’d just like to point out that right now, rig...</td>\n",
       "      <td>631</td>\n",
       "      <td>369</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4112626</td>\n",
       "      <td>1.120000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>GerberKawasaki</td>\n",
       "      <td>18/4/2019</td>\n",
       "      <td>If a Tesla saves you $200 a month on gas, you ...</td>\n",
       "      <td>567</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>567</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4306536</td>\n",
       "      <td>1.200000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>AlexSibila</td>\n",
       "      <td>26/11/2019</td>\n",
       "      <td>~Tesla feature request thread~Feel free to rep...</td>\n",
       "      <td>563</td>\n",
       "      <td>48</td>\n",
       "      <td>662</td>\n",
       "      <td>1273</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2823018</td>\n",
       "      <td>8.860000e+17</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>internet_dust</td>\n",
       "      <td>14/7/2017</td>\n",
       "      <td>\"I sell books.\" versus \"I sell whatever the fu...</td>\n",
       "      <td>496</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>496</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4182686</td>\n",
       "      <td>1.140000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>TeslaNY</td>\n",
       "      <td>13/6/2019</td>\n",
       "      <td>“I think it's basically financially insane to ...</td>\n",
       "      <td>442</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>442</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      tweet_id ticker_symbol          writer   post_date  \\\n",
       "0     3786974  1.010000e+18          TSLA    lopezlinette    5/7/2018   \n",
       "1     4112626  1.120000e+18          TSLA  GerberKawasaki   18/4/2019   \n",
       "2     4306536  1.200000e+18          TSLA      AlexSibila  26/11/2019   \n",
       "3     2823018  8.860000e+17          AMZN   internet_dust   14/7/2017   \n",
       "4     4182686  1.140000e+18          TSLA         TeslaNY   13/6/2019   \n",
       "\n",
       "                                                body  comment_num  \\\n",
       "0  I’d just like to point out that right now, rig...          631   \n",
       "1  If a Tesla saves you $200 a month on gas, you ...          567   \n",
       "2  ~Tesla feature request thread~Feel free to rep...          563   \n",
       "3  \"I sell books.\" versus \"I sell whatever the fu...          496   \n",
       "4  “I think it's basically financially insane to ...          442   \n",
       "\n",
       "   retweet_num  like_num  tweet_activity  sentiment_category  \\\n",
       "0          369         0            1000                   1   \n",
       "1            0         0             567                   1   \n",
       "2           48       662            1273                   1   \n",
       "3            0         0             496                  -1   \n",
       "4            0         0             442                  -1   \n",
       "\n",
       "   subjectivity_category  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      1  \n",
       "3                      1  \n",
       "4                      0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawled_tweets['post_date'] = pd.to_datetime(crawled_tweets['post_date'])\n",
    "crawled_tweets['post_date'] = crawled_tweets['post_date'].dt.date"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to differentiate active tweets which are more \"Reputable\" compared to botting tweets or spams. <br>\n",
    "Activities can be defined as comments/replies, retweets, and likes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>writer</th>\n",
       "      <th>post_date</th>\n",
       "      <th>body</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "      <th>tweet_activity</th>\n",
       "      <th>sentiment_category</th>\n",
       "      <th>subjectivity_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3786974</td>\n",
       "      <td>1.010000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>lopezlinette</td>\n",
       "      <td>5/7/2018</td>\n",
       "      <td>I’d just like to point out that right now, rig...</td>\n",
       "      <td>631</td>\n",
       "      <td>369</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4112626</td>\n",
       "      <td>1.120000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>GerberKawasaki</td>\n",
       "      <td>18/4/2019</td>\n",
       "      <td>If a Tesla saves you $200 a month on gas, you ...</td>\n",
       "      <td>567</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>567</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4306536</td>\n",
       "      <td>1.200000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>AlexSibila</td>\n",
       "      <td>26/11/2019</td>\n",
       "      <td>~Tesla feature request thread~Feel free to rep...</td>\n",
       "      <td>563</td>\n",
       "      <td>48</td>\n",
       "      <td>662</td>\n",
       "      <td>1273</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2823018</td>\n",
       "      <td>8.860000e+17</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>internet_dust</td>\n",
       "      <td>14/7/2017</td>\n",
       "      <td>\"I sell books.\" versus \"I sell whatever the fu...</td>\n",
       "      <td>496</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>496</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4182686</td>\n",
       "      <td>1.140000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>TeslaNY</td>\n",
       "      <td>13/6/2019</td>\n",
       "      <td>“I think it's basically financially insane to ...</td>\n",
       "      <td>442</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>442</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81081</th>\n",
       "      <td>4180147</td>\n",
       "      <td>1.140000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>Dope007</td>\n",
       "      <td>11/6/2019</td>\n",
       "      <td>Fraudulent slip there Musk. Convince investors...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>34</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81082</th>\n",
       "      <td>4176267</td>\n",
       "      <td>1.140000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>TommyThornton</td>\n",
       "      <td>6/6/2019</td>\n",
       "      <td>From the lows your beloved $TSLA only needs to...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81083</th>\n",
       "      <td>4176276</td>\n",
       "      <td>1.140000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>PTBarnu88732123</td>\n",
       "      <td>6/6/2019</td>\n",
       "      <td>Only a total dipshit would compare $tsla stock...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81084</th>\n",
       "      <td>4176239</td>\n",
       "      <td>1.140000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>EthicsGradient</td>\n",
       "      <td>6/6/2019</td>\n",
       "      <td>$TSLA Very big news for China!</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>43</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88044</th>\n",
       "      <td>1488017</td>\n",
       "      <td>1.060000e+18</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>appleinsider</td>\n",
       "      <td>8/11/2018</td>\n",
       "      <td>#Apple's services will grow to over $100 billi...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>45</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88045 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0      tweet_id ticker_symbol           writer   post_date  \\\n",
       "0         3786974  1.010000e+18          TSLA     lopezlinette    5/7/2018   \n",
       "1         4112626  1.120000e+18          TSLA   GerberKawasaki   18/4/2019   \n",
       "2         4306536  1.200000e+18          TSLA       AlexSibila  26/11/2019   \n",
       "3         2823018  8.860000e+17          AMZN    internet_dust   14/7/2017   \n",
       "4         4182686  1.140000e+18          TSLA          TeslaNY   13/6/2019   \n",
       "...           ...           ...           ...              ...         ...   \n",
       "81081     4180147  1.140000e+18          TSLA          Dope007   11/6/2019   \n",
       "81082     4176267  1.140000e+18          TSLA    TommyThornton    6/6/2019   \n",
       "81083     4176276  1.140000e+18          TSLA  PTBarnu88732123    6/6/2019   \n",
       "81084     4176239  1.140000e+18          TSLA   EthicsGradient    6/6/2019   \n",
       "88044     1488017  1.060000e+18          AAPL     appleinsider   8/11/2018   \n",
       "\n",
       "                                                    body  comment_num  \\\n",
       "0      I’d just like to point out that right now, rig...          631   \n",
       "1      If a Tesla saves you $200 a month on gas, you ...          567   \n",
       "2      ~Tesla feature request thread~Feel free to rep...          563   \n",
       "3      \"I sell books.\" versus \"I sell whatever the fu...          496   \n",
       "4      “I think it's basically financially insane to ...          442   \n",
       "...                                                  ...          ...   \n",
       "81081  Fraudulent slip there Musk. Convince investors...            0   \n",
       "81082  From the lows your beloved $TSLA only needs to...            0   \n",
       "81083  Only a total dipshit would compare $tsla stock...            0   \n",
       "81084                     $TSLA Very big news for China!            0   \n",
       "88044  #Apple's services will grow to over $100 billi...            0   \n",
       "\n",
       "       retweet_num  like_num  tweet_activity  sentiment_category  \\\n",
       "0              369         0            1000                   1   \n",
       "1                0         0             567                   1   \n",
       "2               48       662            1273                   1   \n",
       "3                0         0             496                  -1   \n",
       "4                0         0             442                  -1   \n",
       "...            ...       ...             ...                 ...   \n",
       "81081            3        31              34                  -1   \n",
       "81082            0        33              33                   1   \n",
       "81083            2        27              29                   1   \n",
       "81084            9        43              52                   0   \n",
       "88044           10        45              55                   0   \n",
       "\n",
       "       subjectivity_category  \n",
       "0                          0  \n",
       "1                          0  \n",
       "2                          1  \n",
       "3                          1  \n",
       "4                          0  \n",
       "...                      ...  \n",
       "81081                      1  \n",
       "81082                      1  \n",
       "81083                      1  \n",
       "81084                      0  \n",
       "88044                      0  \n",
       "\n",
       "[88045 rows x 12 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.sort_values(by = \"comment_num\" , ascending  = False, inplace = True)\n",
    "tweets\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tweet activities will be defined by the summation of all comments/replies, likes and retweets to differentiate from bots or spams, where tweets are more \"usable\" for sentimental analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>writer</th>\n",
       "      <th>post_date</th>\n",
       "      <th>body</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "      <th>tweet_activity</th>\n",
       "      <th>sentiment_category</th>\n",
       "      <th>subjectivity_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3786974</td>\n",
       "      <td>1.010000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>lopezlinette</td>\n",
       "      <td>5/7/2018</td>\n",
       "      <td>I’d just like to point out that right now, rig...</td>\n",
       "      <td>631</td>\n",
       "      <td>369</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4112626</td>\n",
       "      <td>1.120000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>GerberKawasaki</td>\n",
       "      <td>18/4/2019</td>\n",
       "      <td>If a Tesla saves you $200 a month on gas, you ...</td>\n",
       "      <td>567</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>567</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4306536</td>\n",
       "      <td>1.200000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>AlexSibila</td>\n",
       "      <td>26/11/2019</td>\n",
       "      <td>~Tesla feature request thread~Feel free to rep...</td>\n",
       "      <td>563</td>\n",
       "      <td>48</td>\n",
       "      <td>662</td>\n",
       "      <td>1273</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2823018</td>\n",
       "      <td>8.860000e+17</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>internet_dust</td>\n",
       "      <td>14/7/2017</td>\n",
       "      <td>\"I sell books.\" versus \"I sell whatever the fu...</td>\n",
       "      <td>496</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>496</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4182686</td>\n",
       "      <td>1.140000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>TeslaNY</td>\n",
       "      <td>13/6/2019</td>\n",
       "      <td>“I think it's basically financially insane to ...</td>\n",
       "      <td>442</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>442</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81081</th>\n",
       "      <td>4180147</td>\n",
       "      <td>1.140000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>Dope007</td>\n",
       "      <td>11/6/2019</td>\n",
       "      <td>Fraudulent slip there Musk. Convince investors...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>34</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81082</th>\n",
       "      <td>4176267</td>\n",
       "      <td>1.140000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>TommyThornton</td>\n",
       "      <td>6/6/2019</td>\n",
       "      <td>From the lows your beloved $TSLA only needs to...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81083</th>\n",
       "      <td>4176276</td>\n",
       "      <td>1.140000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>PTBarnu88732123</td>\n",
       "      <td>6/6/2019</td>\n",
       "      <td>Only a total dipshit would compare $tsla stock...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81084</th>\n",
       "      <td>4176239</td>\n",
       "      <td>1.140000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>EthicsGradient</td>\n",
       "      <td>6/6/2019</td>\n",
       "      <td>$TSLA Very big news for China!</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>43</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88044</th>\n",
       "      <td>1488017</td>\n",
       "      <td>1.060000e+18</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>appleinsider</td>\n",
       "      <td>8/11/2018</td>\n",
       "      <td>#Apple's services will grow to over $100 billi...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>45</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88045 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0      tweet_id ticker_symbol           writer   post_date  \\\n",
       "0         3786974  1.010000e+18          TSLA     lopezlinette    5/7/2018   \n",
       "1         4112626  1.120000e+18          TSLA   GerberKawasaki   18/4/2019   \n",
       "2         4306536  1.200000e+18          TSLA       AlexSibila  26/11/2019   \n",
       "3         2823018  8.860000e+17          AMZN    internet_dust   14/7/2017   \n",
       "4         4182686  1.140000e+18          TSLA          TeslaNY   13/6/2019   \n",
       "...           ...           ...           ...              ...         ...   \n",
       "81081     4180147  1.140000e+18          TSLA          Dope007   11/6/2019   \n",
       "81082     4176267  1.140000e+18          TSLA    TommyThornton    6/6/2019   \n",
       "81083     4176276  1.140000e+18          TSLA  PTBarnu88732123    6/6/2019   \n",
       "81084     4176239  1.140000e+18          TSLA   EthicsGradient    6/6/2019   \n",
       "88044     1488017  1.060000e+18          AAPL     appleinsider   8/11/2018   \n",
       "\n",
       "                                                    body  comment_num  \\\n",
       "0      I’d just like to point out that right now, rig...          631   \n",
       "1      If a Tesla saves you $200 a month on gas, you ...          567   \n",
       "2      ~Tesla feature request thread~Feel free to rep...          563   \n",
       "3      \"I sell books.\" versus \"I sell whatever the fu...          496   \n",
       "4      “I think it's basically financially insane to ...          442   \n",
       "...                                                  ...          ...   \n",
       "81081  Fraudulent slip there Musk. Convince investors...            0   \n",
       "81082  From the lows your beloved $TSLA only needs to...            0   \n",
       "81083  Only a total dipshit would compare $tsla stock...            0   \n",
       "81084                     $TSLA Very big news for China!            0   \n",
       "88044  #Apple's services will grow to over $100 billi...            0   \n",
       "\n",
       "       retweet_num  like_num  tweet_activity  sentiment_category  \\\n",
       "0              369         0            1000                   1   \n",
       "1                0         0             567                   1   \n",
       "2               48       662            1273                   1   \n",
       "3                0         0             496                  -1   \n",
       "4                0         0             442                  -1   \n",
       "...            ...       ...             ...                 ...   \n",
       "81081            3        31              34                  -1   \n",
       "81082            0        33              33                   1   \n",
       "81083            2        27              29                   1   \n",
       "81084            9        43              52                   0   \n",
       "88044           10        45              55                   0   \n",
       "\n",
       "       subjectivity_category  \n",
       "0                          0  \n",
       "1                          0  \n",
       "2                          1  \n",
       "3                          1  \n",
       "4                          0  \n",
       "...                      ...  \n",
       "81081                      1  \n",
       "81082                      1  \n",
       "81083                      1  \n",
       "81084                      0  \n",
       "88044                      0  \n",
       "\n",
       "[88045 rows x 12 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[\"tweet_activity\"] = tweets[\"comment_num\"] + tweets[\"like_num\"] + tweets[\"retweet_num\"]\n",
    "tweets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Tweets that are >= 25 activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterTweets = tweets.loc[tweets[\"tweet_activity\"] > 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>writer</th>\n",
       "      <th>post_date</th>\n",
       "      <th>body</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "      <th>tweet_activity</th>\n",
       "      <th>sentiment_category</th>\n",
       "      <th>subjectivity_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3786974</td>\n",
       "      <td>1.010000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>lopezlinette</td>\n",
       "      <td>5/7/2018</td>\n",
       "      <td>I’d just like to point out that right now, rig...</td>\n",
       "      <td>631</td>\n",
       "      <td>369</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4112626</td>\n",
       "      <td>1.120000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>GerberKawasaki</td>\n",
       "      <td>18/4/2019</td>\n",
       "      <td>If a Tesla saves you $200 a month on gas, you ...</td>\n",
       "      <td>567</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>567</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4306536</td>\n",
       "      <td>1.200000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>AlexSibila</td>\n",
       "      <td>26/11/2019</td>\n",
       "      <td>~Tesla feature request thread~Feel free to rep...</td>\n",
       "      <td>563</td>\n",
       "      <td>48</td>\n",
       "      <td>662</td>\n",
       "      <td>1273</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2823018</td>\n",
       "      <td>8.860000e+17</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>internet_dust</td>\n",
       "      <td>14/7/2017</td>\n",
       "      <td>\"I sell books.\" versus \"I sell whatever the fu...</td>\n",
       "      <td>496</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>496</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4182686</td>\n",
       "      <td>1.140000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>TeslaNY</td>\n",
       "      <td>13/6/2019</td>\n",
       "      <td>“I think it's basically financially insane to ...</td>\n",
       "      <td>442</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>442</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      tweet_id ticker_symbol          writer   post_date  \\\n",
       "0     3786974  1.010000e+18          TSLA    lopezlinette    5/7/2018   \n",
       "1     4112626  1.120000e+18          TSLA  GerberKawasaki   18/4/2019   \n",
       "2     4306536  1.200000e+18          TSLA      AlexSibila  26/11/2019   \n",
       "3     2823018  8.860000e+17          AMZN   internet_dust   14/7/2017   \n",
       "4     4182686  1.140000e+18          TSLA         TeslaNY   13/6/2019   \n",
       "\n",
       "                                                body  comment_num  \\\n",
       "0  I’d just like to point out that right now, rig...          631   \n",
       "1  If a Tesla saves you $200 a month on gas, you ...          567   \n",
       "2  ~Tesla feature request thread~Feel free to rep...          563   \n",
       "3  \"I sell books.\" versus \"I sell whatever the fu...          496   \n",
       "4  “I think it's basically financially insane to ...          442   \n",
       "\n",
       "   retweet_num  like_num  tweet_activity  sentiment_category  \\\n",
       "0          369         0            1000                   1   \n",
       "1            0         0             567                   1   \n",
       "2           48       662            1273                   1   \n",
       "3            0         0             496                  -1   \n",
       "4            0         0             442                  -1   \n",
       "\n",
       "   subjectivity_category  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      1  \n",
       "3                      1  \n",
       "4                      0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filterTweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "      <th>tweet_activity</th>\n",
       "      <th>sentiment_category</th>\n",
       "      <th>subjectivity_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.804500e+04</td>\n",
       "      <td>8.804500e+04</td>\n",
       "      <td>88045.000000</td>\n",
       "      <td>88045.000000</td>\n",
       "      <td>88045.000000</td>\n",
       "      <td>88045.000000</td>\n",
       "      <td>88045.000000</td>\n",
       "      <td>88045.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.266381e+06</td>\n",
       "      <td>1.037548e+18</td>\n",
       "      <td>6.009790</td>\n",
       "      <td>17.359135</td>\n",
       "      <td>58.161804</td>\n",
       "      <td>81.530729</td>\n",
       "      <td>0.285763</td>\n",
       "      <td>0.315566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.165772e+06</td>\n",
       "      <td>1.434625e+17</td>\n",
       "      <td>11.197338</td>\n",
       "      <td>45.525474</td>\n",
       "      <td>75.893739</td>\n",
       "      <td>104.740242</td>\n",
       "      <td>0.773832</td>\n",
       "      <td>0.464743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000e+01</td>\n",
       "      <td>5.500000e+17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.490996e+06</td>\n",
       "      <td>9.960000e+17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.867796e+06</td>\n",
       "      <td>1.070000e+18</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.112427e+06</td>\n",
       "      <td>1.130000e+18</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.336399e+06</td>\n",
       "      <td>1.210000e+18</td>\n",
       "      <td>631.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>1703.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0      tweet_id   comment_num   retweet_num      like_num  \\\n",
       "count  8.804500e+04  8.804500e+04  88045.000000  88045.000000  88045.000000   \n",
       "mean   3.266381e+06  1.037548e+18      6.009790     17.359135     58.161804   \n",
       "std    1.165772e+06  1.434625e+17     11.197338     45.525474     75.893739   \n",
       "min    4.000000e+01  5.500000e+17      0.000000      0.000000      0.000000   \n",
       "25%    2.490996e+06  9.960000e+17      1.000000      4.000000     24.000000   \n",
       "50%    3.867796e+06  1.070000e+18      3.000000      8.000000     35.000000   \n",
       "75%    4.112427e+06  1.130000e+18      7.000000     17.000000     61.000000   \n",
       "max    4.336399e+06  1.210000e+18    631.000000    999.000000    999.000000   \n",
       "\n",
       "       tweet_activity  sentiment_category  subjectivity_category  \n",
       "count    88045.000000        88045.000000           88045.000000  \n",
       "mean        81.530729            0.285763               0.315566  \n",
       "std        104.740242            0.773832               0.464743  \n",
       "min         26.000000           -1.000000               0.000000  \n",
       "25%         34.000000            0.000000               0.000000  \n",
       "50%         48.000000            0.000000               0.000000  \n",
       "75%         84.000000            1.000000               1.000000  \n",
       "max       1703.000000            1.000000               1.000000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filterTweets.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning and Tokenization of text body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove stopwords (common english stopwords from nltk)\n",
    "def removeStopWords(df):\n",
    "    finalList = []\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    negativeList = ['not','no', 'nor']\n",
    "    for x in negativeList:\n",
    "        stop_words.remove(x)\n",
    "    for word in df:\n",
    "        if word not in stop_words:\n",
    "            finalList.append(word)\n",
    "    df = finalList\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to stem tweets \n",
    "def stem_text(text):\n",
    "    \n",
    "    stemmer = PorterStemmer()\n",
    "   \n",
    "    return [stemmer.stem(word) for word in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to lemmatise tweets\n",
    "def lemmatised_text(text):\n",
    "    lemmatiser = nltk.stem.WordNetLemmatizer()\n",
    "    return [lemmatiser.lemmatize(word) for word in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_contractions(text):\n",
    "    expanded_text = contractions.fix(text)\n",
    "    return expanded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_username(text):\n",
    "    return re.sub(r'@\\w+', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_hashtag(text):\n",
    "    return re.sub(r'#\\w+', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataframe_text(df, column,lemma):\n",
    "    \n",
    "    # Define regex pattern to match URLs\n",
    "    url_pattern = r\"https?://\\S+\"\n",
    "    # Remove URLs from text column\n",
    "    df[column] = df[column].str.replace(url_pattern, \"\", regex=True)\n",
    "    # Remove username from text column\n",
    "    df[column] = df[column].apply(lambda x: remove_username(x))\n",
    "     # Remove hashtag from text column\n",
    "    df[column] = df[column].apply(lambda x: remove_hashtag(x))\n",
    "    # Replace Contractions\n",
    "    df[column] = df[column].apply(lambda x: replace_contractions(x))\n",
    "    # Remove any non-alphanumeric characters and replace them with spaces\n",
    "    df[column] = df[column].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "    # Replace any consecutive whitespace characters with a single space\n",
    "    df[column] = df[column].apply(lambda x: re.sub(r'\\s+', ' ', x))\n",
    "    # Remove not word characters\n",
    "    df[column] = df[column].apply(lambda x: re.sub(r'[^\\w\\s]', ' ', x))\n",
    "    # Remove digits \n",
    "    df[column] = df[column].apply(lambda x: re.sub(r'\\d+', '', x))\n",
    "    # Convert the string in lower\n",
    "    df[column] = df[column].str.lower()\n",
    "    # Tokenised the words\n",
    "    df[column]  = df[column].apply(lambda x : nltk.word_tokenize(x))\n",
    "    # Remove stopwords from the NLTK stopword list\n",
    "    df[column] = df[column].apply(lambda x : removeStopWords(x))\n",
    "    if lemma:\n",
    "    # lemmatised the text\n",
    "        df[column] = df[column].apply(lambda x : lemmatised_text(x))\n",
    "    else:\n",
    "    # Stemmed the text\n",
    "        df[column] = df[column].apply(lambda x : stem_text(x))\n",
    "    #concatenate the tokenised list into string\n",
    "    df[column] = df[column].apply(lambda x: ' '.join(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>writer</th>\n",
       "      <th>post_date</th>\n",
       "      <th>body</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "      <th>tweet_activity</th>\n",
       "      <th>sentiment_category</th>\n",
       "      <th>subjectivity_category</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3786974</td>\n",
       "      <td>1.010000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>lopezlinette</td>\n",
       "      <td>5/7/2018</td>\n",
       "      <td>I’d just like to point out that right now, rig...</td>\n",
       "      <td>631</td>\n",
       "      <td>369</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>would like point right right moment going face...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4112626</td>\n",
       "      <td>1.120000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>GerberKawasaki</td>\n",
       "      <td>18/4/2019</td>\n",
       "      <td>If a Tesla saves you $200 a month on gas, you ...</td>\n",
       "      <td>567</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>567</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>tesla save month gas ten year take saving put ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4306536</td>\n",
       "      <td>1.200000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>AlexSibila</td>\n",
       "      <td>26/11/2019</td>\n",
       "      <td>~Tesla feature request thread~Feel free to rep...</td>\n",
       "      <td>563</td>\n",
       "      <td>48</td>\n",
       "      <td>662</td>\n",
       "      <td>1273</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>tesla feature request threadfeel free reply co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2823018</td>\n",
       "      <td>8.860000e+17</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>internet_dust</td>\n",
       "      <td>14/7/2017</td>\n",
       "      <td>\"I sell books.\" versus \"I sell whatever the fu...</td>\n",
       "      <td>496</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>496</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>sell book versus sell whatever fuck want amzn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4182686</td>\n",
       "      <td>1.140000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>TeslaNY</td>\n",
       "      <td>13/6/2019</td>\n",
       "      <td>“I think it's basically financially insane to ...</td>\n",
       "      <td>442</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>442</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>think basically financially insane buy anythin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      tweet_id ticker_symbol          writer   post_date  \\\n",
       "0     3786974  1.010000e+18          TSLA    lopezlinette    5/7/2018   \n",
       "1     4112626  1.120000e+18          TSLA  GerberKawasaki   18/4/2019   \n",
       "2     4306536  1.200000e+18          TSLA      AlexSibila  26/11/2019   \n",
       "3     2823018  8.860000e+17          AMZN   internet_dust   14/7/2017   \n",
       "4     4182686  1.140000e+18          TSLA         TeslaNY   13/6/2019   \n",
       "\n",
       "                                                body  comment_num  \\\n",
       "0  I’d just like to point out that right now, rig...          631   \n",
       "1  If a Tesla saves you $200 a month on gas, you ...          567   \n",
       "2  ~Tesla feature request thread~Feel free to rep...          563   \n",
       "3  \"I sell books.\" versus \"I sell whatever the fu...          496   \n",
       "4  “I think it's basically financially insane to ...          442   \n",
       "\n",
       "   retweet_num  like_num  tweet_activity  sentiment_category  \\\n",
       "0          369         0            1000                   1   \n",
       "1            0         0             567                   1   \n",
       "2           48       662            1273                   1   \n",
       "3            0         0             496                  -1   \n",
       "4            0         0             442                  -1   \n",
       "\n",
       "   subjectivity_category                                         clean_text  \n",
       "0                      0  would like point right right moment going face...  \n",
       "1                      0  tesla save month gas ten year take saving put ...  \n",
       "2                      1  tesla feature request threadfeel free reply co...  \n",
       "3                      1      sell book versus sell whatever fuck want amzn  \n",
       "4                      0  think basically financially insane buy anythin...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tweets that are cleaned and stemmed\n",
    "filterTweets['clean_text'] = filterTweets['body']\n",
    "filterTweets = clean_dataframe_text(filterTweets,\"clean_text\",True)\n",
    "filterTweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawled_tweets['clean_text'] = crawled_tweets['body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "crawled_tweets = clean_dataframe_text(crawled_tweets,\"clean_text\",True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Positive, Negative and Neutral to numeral labels and Subjectivity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting up data for Prediction using ensemble machine learning models For Blob Subjectivity and Polarity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = filterTweets[\"clean_text\"].values \n",
    "y = filterTweets[[\"sentiment_category\"]].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_subj = filterTweets[\"clean_text\"].values \n",
    "y_subj = filterTweets[\"subjectivity_category\"].values\n",
    "X_train_subj, X_test_subj, y_train_subj, y_test_subj = train_test_split(\n",
    "    X_subj, y_subj, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    60261\n",
       "1    27784\n",
       "Name: subjectivity_category, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filterTweets[\"subjectivity_category\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Data -> Crawled and labelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evluation Data for Subjectivity\n",
    "eval_data_x = crawled_tweets['clean_text'].values\n",
    "eval_data_y = crawled_tweets['vote_subjectivity'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_report(y_test,y_pred,time,no_record_x_test,y_eval, y_pred_eval,time_eval,no_record_x_eval):\n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    fmeasure = f1_score(y_test,y_pred, average = \"weighted\", zero_division = 1)\n",
    "    recall = recall_score(y_test, y_pred, average = \"weighted\",zero_division = 1)\n",
    "    precision = precision_score(y_test, y_pred, average = \"weighted\",zero_division = 1)\n",
    "\n",
    "    \n",
    "    print(f\"Model Metrics with testing data\")\n",
    "    print(f\"The accuracy of the Model is {accuracy}\")\n",
    "    print(f\"The F-Score of the Model is {fmeasure}\")\n",
    "    print(f\"The Recall of the Model is {recall}\")\n",
    "    print(f\"The precision of the Model is {precision}\")\n",
    "    print(f\"The time taken for the Model prediction is {time} seconds\")\n",
    "    print(f\"The number of records per second is {no_record_x_test//time}\")\n",
    "    print(f\"================================================================\")\n",
    "    \n",
    "\n",
    "    accuracy_eval = accuracy_score(y_eval,y_pred_eval)\n",
    "    fmeasure_eval = f1_score(y_eval,y_pred_eval, average = \"weighted\", zero_division = 1)\n",
    "    recall_eval = recall_score(y_eval, y_pred_eval, average = \"weighted\",zero_division = 1)\n",
    "    precision_eval = precision_score(y_eval, y_pred_eval, average = \"weighted\",zero_division = 1)\n",
    "    print(f\"Model Metrics with evaluation data\")\n",
    "    print(f\"The accuracy of the Model is {accuracy_eval}\")\n",
    "    print(f\"The F-Score of the Model is {fmeasure_eval}\")\n",
    "    print(f\"The Recall of the Model is {recall_eval}\")\n",
    "    print(f\"The precision of the Model is {precision_eval}\")\n",
    "    print(f\"The time taken for the Model prediction is {time_eval} seconds\")\n",
    "    print(f\"The number of records per second is {no_record_x_eval//time_eval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_report_noeval(y_test,y_pred,time,no_record_x_test):\n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    fmeasure = f1_score(y_test,y_pred, average = \"weighted\", zero_division = 1)\n",
    "    recall = recall_score(y_test, y_pred, average = \"weighted\",zero_division = 1)\n",
    "    precision = precision_score(y_test, y_pred, average = \"weighted\",zero_division = 1)\n",
    "\n",
    "    \n",
    "    print(f\"Model Metrics with testing data\")\n",
    "    print(f\"The accuracy of the Model is {accuracy}\")\n",
    "    print(f\"The F-Score of the Model is {fmeasure}\")\n",
    "    print(f\"The Recall of the Model is {recall}\")\n",
    "    print(f\"The precision of the Model is {precision}\")\n",
    "    print(f\"The time taken for the Model prediction is {time} seconds\")\n",
    "    print(f\"The number of records per second is {no_record_x_test//time}\")\n",
    "    print(f\"================================================================\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorise and TFIDF train and test datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Count Vectorizer (TF)\n",
    "vectoriser = CountVectorizer()\n",
    "\n",
    "# For blob analysis dataset that have been lemmatised\n",
    "\n",
    "X_train_vec = vectoriser.fit_transform(X_train)\n",
    "X_test_vec = vectoriser.transform(X_test)\n",
    "eval_data_x_vec = vectoriser.transform(eval_data_x)\n",
    "\n",
    "\n",
    "# For Subjectivity Blob Analysis Vectorised\n",
    "X_train_subj_vec = vectoriser.fit_transform(X_train_subj)\n",
    "X_test_subj_vec = vectoriser.transform(X_test_subj)\n",
    "eval_data_x_subj_vec = vectoriser.transform(eval_data_x)\n",
    "\n",
    "\n",
    "# Create TFID Vectorizer \n",
    "vectoriser_tfidf = TfidfVectorizer()\n",
    "# For blob analysis dataset that have been lemmatised\n",
    "\n",
    "\n",
    "X_train_tfidf = vectoriser_tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = vectoriser_tfidf.transform(X_test)\n",
    "eval_data_x_tfidf = vectoriser_tfidf.transform(eval_data_x)\n",
    "\n",
    "# For Subjectivity Blob Analysis TFIDF\n",
    "X_train_subj_tfidf = vectoriser_tfidf.fit_transform(X_train_subj)\n",
    "X_test_subj_tfidf = vectoriser_tfidf.transform(X_test_subj)\n",
    "eval_data_x_subj_tfidf = vectoriser_tfidf.transform(eval_data_x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterSubjTweets = filterTweets.copy()\n",
    "filterSubjTweets = filterSubjTweets.loc[filterSubjTweets['subjectivity_category'] == 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterSubjTweets = filterSubjTweets.loc[filterSubjTweets['sentiment_category'] != 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_map_self = {-1 : 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterSubjTweets[\"sentiment_category\"].replace(sentiment_map_self, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>writer</th>\n",
       "      <th>post_date</th>\n",
       "      <th>body</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "      <th>tweet_activity</th>\n",
       "      <th>sentiment_category</th>\n",
       "      <th>subjectivity_category</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4306536</td>\n",
       "      <td>1.200000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>AlexSibila</td>\n",
       "      <td>26/11/2019</td>\n",
       "      <td>~Tesla feature request thread~Feel free to rep...</td>\n",
       "      <td>563</td>\n",
       "      <td>48</td>\n",
       "      <td>662</td>\n",
       "      <td>1273</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>tesla feature request threadfeel free reply co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2823018</td>\n",
       "      <td>8.860000e+17</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>internet_dust</td>\n",
       "      <td>14/7/2017</td>\n",
       "      <td>\"I sell books.\" versus \"I sell whatever the fu...</td>\n",
       "      <td>496</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>496</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>sell book versus sell whatever fuck want amzn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4276279</td>\n",
       "      <td>1.190000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>jack</td>\n",
       "      <td>24/10/2019</td>\n",
       "      <td>Now anyone can buy $42 or even $1 worth of Ber...</td>\n",
       "      <td>298</td>\n",
       "      <td>589</td>\n",
       "      <td>0</td>\n",
       "      <td>887</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>anyone buy even worth berkshire hathaway brka ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4076527</td>\n",
       "      <td>1.110000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>ElectricTempus</td>\n",
       "      <td>17/3/2019</td>\n",
       "      <td>People are buying Tesla’s, in their Tesla’s.  ...</td>\n",
       "      <td>292</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>292</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>people buying tesla tesla many reason love com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3750143</td>\n",
       "      <td>1.000000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>MattLevinson</td>\n",
       "      <td>25/5/2018</td>\n",
       "      <td>Thank you @elonmusk and @tesla for by FAR the ...</td>\n",
       "      <td>290</td>\n",
       "      <td>840</td>\n",
       "      <td>0</td>\n",
       "      <td>1130</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>thank far best consumer product ever used day ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81079</th>\n",
       "      <td>4179793</td>\n",
       "      <td>1.140000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>Polixenes13</td>\n",
       "      <td>11/6/2019</td>\n",
       "      <td>$TSLA's Nevada Gigafactory is a fine place for...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>tslas nevada gigafactory fine place making cyl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81080</th>\n",
       "      <td>4180250</td>\n",
       "      <td>1.140000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>PlugInFUD</td>\n",
       "      <td>11/6/2019</td>\n",
       "      <td>\"this is quite a hard problem. ignore that we ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>quite hard problem ignore completely fabricate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81081</th>\n",
       "      <td>4180147</td>\n",
       "      <td>1.140000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>Dope007</td>\n",
       "      <td>11/6/2019</td>\n",
       "      <td>Fraudulent slip there Musk. Convince investors...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>fraudulent slip musk convince investor oops me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81082</th>\n",
       "      <td>4176267</td>\n",
       "      <td>1.140000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>TommyThornton</td>\n",
       "      <td>6/6/2019</td>\n",
       "      <td>From the lows your beloved $TSLA only needs to...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>low beloved tsla need go get old high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81083</th>\n",
       "      <td>4176276</td>\n",
       "      <td>1.140000e+18</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>PTBarnu88732123</td>\n",
       "      <td>6/6/2019</td>\n",
       "      <td>Only a total dipshit would compare $tsla stock...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>total dipshit would compare tsla stock price m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25880 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0      tweet_id ticker_symbol           writer   post_date  \\\n",
       "2         4306536  1.200000e+18          TSLA       AlexSibila  26/11/2019   \n",
       "3         2823018  8.860000e+17          AMZN    internet_dust   14/7/2017   \n",
       "11        4276279  1.190000e+18          TSLA             jack  24/10/2019   \n",
       "12        4076527  1.110000e+18          TSLA   ElectricTempus   17/3/2019   \n",
       "13        3750143  1.000000e+18          TSLA     MattLevinson   25/5/2018   \n",
       "...           ...           ...           ...              ...         ...   \n",
       "81079     4179793  1.140000e+18          TSLA      Polixenes13   11/6/2019   \n",
       "81080     4180250  1.140000e+18          TSLA        PlugInFUD   11/6/2019   \n",
       "81081     4180147  1.140000e+18          TSLA          Dope007   11/6/2019   \n",
       "81082     4176267  1.140000e+18          TSLA    TommyThornton    6/6/2019   \n",
       "81083     4176276  1.140000e+18          TSLA  PTBarnu88732123    6/6/2019   \n",
       "\n",
       "                                                    body  comment_num  \\\n",
       "2      ~Tesla feature request thread~Feel free to rep...          563   \n",
       "3      \"I sell books.\" versus \"I sell whatever the fu...          496   \n",
       "11     Now anyone can buy $42 or even $1 worth of Ber...          298   \n",
       "12     People are buying Tesla’s, in their Tesla’s.  ...          292   \n",
       "13     Thank you @elonmusk and @tesla for by FAR the ...          290   \n",
       "...                                                  ...          ...   \n",
       "81079  $TSLA's Nevada Gigafactory is a fine place for...            0   \n",
       "81080  \"this is quite a hard problem. ignore that we ...            0   \n",
       "81081  Fraudulent slip there Musk. Convince investors...            0   \n",
       "81082  From the lows your beloved $TSLA only needs to...            0   \n",
       "81083  Only a total dipshit would compare $tsla stock...            0   \n",
       "\n",
       "       retweet_num  like_num  tweet_activity  sentiment_category  \\\n",
       "2               48       662            1273                   1   \n",
       "3                0         0             496                   0   \n",
       "11             589         0             887                   1   \n",
       "12               0         0             292                   1   \n",
       "13             840         0            1130                   1   \n",
       "...            ...       ...             ...                 ...   \n",
       "81079            7        33              40                   0   \n",
       "81080            4        26              30                   1   \n",
       "81081            3        31              34                   0   \n",
       "81082            0        33              33                   1   \n",
       "81083            2        27              29                   1   \n",
       "\n",
       "       subjectivity_category  \\\n",
       "2                          1   \n",
       "3                          1   \n",
       "11                         1   \n",
       "12                         1   \n",
       "13                         1   \n",
       "...                      ...   \n",
       "81079                      1   \n",
       "81080                      1   \n",
       "81081                      1   \n",
       "81082                      1   \n",
       "81083                      1   \n",
       "\n",
       "                                              clean_text  \n",
       "2      tesla feature request threadfeel free reply co...  \n",
       "3          sell book versus sell whatever fuck want amzn  \n",
       "11     anyone buy even worth berkshire hathaway brka ...  \n",
       "12     people buying tesla tesla many reason love com...  \n",
       "13     thank far best consumer product ever used day ...  \n",
       "...                                                  ...  \n",
       "81079  tslas nevada gigafactory fine place making cyl...  \n",
       "81080  quite hard problem ignore completely fabricate...  \n",
       "81081  fraudulent slip musk convince investor oops me...  \n",
       "81082              low beloved tsla need go get old high  \n",
       "81083  total dipshit would compare tsla stock price m...  \n",
       "\n",
       "[25880 rows x 13 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filterSubjTweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = filterSubjTweets[\"clean_text\"].values \n",
    "y = filterSubjTweets[\"sentiment_category\"].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawled_tweets = crawled_tweets.loc[crawled_tweets['vote_subjectivity'] != 0]\n",
    "crawled_tweets = crawled_tweets.loc[crawled_tweets['vote_sentiment'] != 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawled_tweets[\"vote_sentiment\"].replace(sentiment_map_self, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evluation Data for Subjectivity\n",
    "eval_data_x = crawled_tweets['clean_text'].values\n",
    "eval_data_y_polarity = crawled_tweets['vote_sentiment'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Count Vectorizer (TF)\n",
    "vectoriser = CountVectorizer()\n",
    "\n",
    "# For blob analysis dataset that have been lemmatised\n",
    "\n",
    "X_train_vec = vectoriser.fit_transform(X_train)\n",
    "X_test_vec = vectoriser.transform(X_test)\n",
    "eval_data_x_vec = vectoriser.transform(eval_data_x)\n",
    "\n",
    "\n",
    "# Create TFID Vectorizer \n",
    "vectoriser_tfidf = TfidfVectorizer()\n",
    "# For blob analysis dataset that have been lemmatised\n",
    "\n",
    "X_train_tfidf = vectoriser_tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = vectoriser_tfidf.transform(X_test)\n",
    "eval_data_x_tfidf = vectoriser_tfidf.transform(eval_data_x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = \"binary_crossentropy\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Stacked for NN MLP SVC and LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(X_shape):\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape = (X_shape.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-5, l2=1e-4)),\n",
    "    tf.keras.layers.Dropout(rate=0.5),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-5, l2=1e-4)),\n",
    "    tf.keras.layers.Dropout(rate=0.5),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-5, l2=1e-4)),\n",
    "    tf.keras.layers.Dropout(rate=0.5),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-5, l2=1e-4)),\n",
    "    tf.keras.layers.Dropout(rate=0.5),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "    # Compile the model_tfidf\n",
    "    model.compile(loss=loss, optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "    model._estimator_type = 'classifier'\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Metrics with testing data\n",
      "The accuracy of the Model is 0.892774343122102\n",
      "The F-Score of the Model is 0.8914227310463367\n",
      "The Recall of the Model is 0.892774343122102\n",
      "The precision of the Model is 0.8911691169882233\n",
      "The time taken for the Model prediction is 11.35392689704895 seconds\n",
      "The number of records per second is 455.0\n",
      "================================================================\n",
      "Model Metrics with evaluation data\n",
      "The accuracy of the Model is 0.8574821852731591\n",
      "The F-Score of the Model is 0.8490992368056043\n",
      "The Recall of the Model is 0.8574821852731591\n",
      "The precision of the Model is 0.8568287436770348\n",
      "The time taken for the Model prediction is 1.5064880847930908 seconds\n",
      "The number of records per second is 558.0\n"
     ]
    }
   ],
   "source": [
    "# Start Training with Count Vectoriser\n",
    "\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "# Train several other models on your data using different algorithms or hyperparameters\n",
    "lr = LogisticRegression(max_iter = 1000)\n",
    "svm = SVC(kernel = \"rbf\", random_state = 1)\n",
    "nn = MLPClassifier(solver = \"adam\", alpha = 1e-5, \n",
    "                   hidden_layer_sizes =(64,2), activation = 'tanh',  max_iter = 1000, early_stopping = True)\n",
    "\n",
    "# Use these models to make predictions on your data\n",
    "lr.fit(X_train_vec,y_train)\n",
    "svm.fit(X_train_vec,y_train)\n",
    "nn.fit(X_train_vec,y_train)\n",
    "\n",
    "meta_model = LogisticRegression()\n",
    "stacking_model = StackingClassifier(classifiers=[lr, svm, nn], meta_classifier=meta_model)\n",
    "stacking_model.fit(X_train_vec, y_train)\n",
    "start_time = time.time()\n",
    "y_pred = stacking_model.predict(X_test_vec)\n",
    "end_time = time.time()\n",
    "y_pred = (y_pred >= 0.5).astype(int)\n",
    "\n",
    "\n",
    "start_time_eval = time.time()\n",
    "y_pred_eval = stacking_model.predict(eval_data_x_vec)\n",
    "end_time_eval = time.time()\n",
    "time_taken_eval =  end_time_eval - start_time_eval\n",
    "y_pred_eval = (y_pred_eval >= 0.5).astype(int)\n",
    "\n",
    "metric_report(y_test,y_pred,time_taken,len(y_test), eval_data_y_polarity, y_pred_eval, time_taken_eval, len(eval_data_y_polarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Metrics with testing data\n",
      "The accuracy of the Model is 0.874613601236476\n",
      "The F-Score of the Model is 0.86827084864194\n",
      "The Recall of the Model is 0.874613601236476\n",
      "The precision of the Model is 0.8754627054698726\n",
      "The time taken for the Model prediction is 0.5272204875946045 seconds\n",
      "The number of records per second is 9817.0\n",
      "================================================================\n",
      "Model Metrics with evaluation data\n",
      "The accuracy of the Model is 0.8479809976247031\n",
      "The F-Score of the Model is 0.8339784532507322\n",
      "The Recall of the Model is 0.8479809976247031\n",
      "The precision of the Model is 0.854245758640058\n",
      "The time taken for the Model prediction is 2.2750065326690674 seconds\n",
      "The number of records per second is 370.0\n"
     ]
    }
   ],
   "source": [
    "# Start Training with tfidf_vectorizer\n",
    "\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "# Train several other models on your data using different algorithms or hyperparameters\n",
    "lr = LogisticRegression(max_iter = 1000)\n",
    "svm = SVC(kernel = \"rbf\", random_state = 1)\n",
    "nn = MLPClassifier(solver = \"adam\", alpha = 1e-5, \n",
    "                    hidden_layer_sizes =(64,2), activation = 'tanh',  max_iter = 1000, early_stopping = True)\n",
    "\n",
    "# Use these models to make predictions on your data\n",
    "lr.fit(X_train_tfidf,y_train)\n",
    "svm.fit(X_train_tfidf,y_train)\n",
    "nn.fit(X_train_tfidf,y_train)\n",
    "\n",
    "meta_model = LogisticRegression()\n",
    "stacking_model = StackingClassifier(classifiers=[lr, svm, nn], meta_classifier=meta_model)\n",
    "stacking_model.fit(X_train_tfidf, y_train)\n",
    "start_time = time.time()\n",
    "y_pred = stacking_model.predict(X_test_tfidf)\n",
    "end_time = time.time()\n",
    "y_pred = (y_pred >= 0.5).astype(int)\n",
    "time_taken = end_time - start_time\n",
    "\n",
    "start_time_eval = time.time()\n",
    "y_pred_eval = stacking_model.predict(eval_data_x_tfidf)\n",
    "end_time_eval = time.time()\n",
    "time_taken_eval =  end_time_eval - start_time_eval\n",
    "y_pred_eval = (y_pred_eval >= 0.5).astype(int)\n",
    "\n",
    "metric_report(y_test,y_pred,time_taken,len(y_test), eval_data_y_polarity, y_pred_eval, time_taken_eval, len(eval_data_y_polarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "647/647 [==============================] - 21s 31ms/step - loss: 0.5373 - accuracy: 0.8014\n",
      "Epoch 2/5\n",
      "647/647 [==============================] - 23s 35ms/step - loss: 0.3829 - accuracy: 0.9058\n",
      "Epoch 3/5\n",
      "647/647 [==============================] - 23s 36ms/step - loss: 0.3127 - accuracy: 0.9393\n",
      "Epoch 4/5\n",
      "647/647 [==============================] - 24s 37ms/step - loss: 0.2776 - accuracy: 0.9531\n",
      "Epoch 5/5\n",
      "647/647 [==============================] - 23s 36ms/step - loss: 0.2581 - accuracy: 0.9610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\eric2\\AppData\\Local\\Temp\\tmpt5lv0awn\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\eric2\\AppData\\Local\\Temp\\tmpt5lv0awn\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "647/647 [==============================] - 21s 32ms/step - loss: 0.2463 - accuracy: 0.9637\n",
      "Epoch 2/5\n",
      "647/647 [==============================] - 21s 33ms/step - loss: 0.2458 - accuracy: 0.9640\n",
      "Epoch 3/5\n",
      "647/647 [==============================] - 20s 31ms/step - loss: 0.2352 - accuracy: 0.9680\n",
      "Epoch 4/5\n",
      "647/647 [==============================] - 20s 32ms/step - loss: 0.2354 - accuracy: 0.9680\n",
      "Epoch 5/5\n",
      "647/647 [==============================] - 22s 34ms/step - loss: 0.2290 - accuracy: 0.9705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\eric2\\AppData\\Local\\Temp\\tmph98o2ukg\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\eric2\\AppData\\Local\\Temp\\tmph98o2ukg\\assets\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\eric2\\AppData\\Local\\Temp\\tmp7xb5uwet\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\eric2\\AppData\\Local\\Temp\\tmp7xb5uwet\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "518/518 [==============================] - 17s 32ms/step - loss: 0.2413 - accuracy: 0.9656\n",
      "Epoch 2/5\n",
      "518/518 [==============================] - 17s 32ms/step - loss: 0.2307 - accuracy: 0.9688\n",
      "Epoch 3/5\n",
      "518/518 [==============================] - 17s 32ms/step - loss: 0.2260 - accuracy: 0.9686\n",
      "Epoch 4/5\n",
      "518/518 [==============================] - 16s 32ms/step - loss: 0.2126 - accuracy: 0.9752\n",
      "Epoch 5/5\n",
      "518/518 [==============================] - 16s 32ms/step - loss: 0.2150 - accuracy: 0.9730\n",
      "130/130 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\eric2\\AppData\\Local\\Temp\\tmp9ihw_ty9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\eric2\\AppData\\Local\\Temp\\tmp9ihw_ty9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "518/518 [==============================] - 18s 33ms/step - loss: 0.2348 - accuracy: 0.9683\n",
      "Epoch 2/5\n",
      "518/518 [==============================] - 17s 33ms/step - loss: 0.2309 - accuracy: 0.9684\n",
      "Epoch 3/5\n",
      "518/518 [==============================] - 17s 33ms/step - loss: 0.2203 - accuracy: 0.9711\n",
      "Epoch 4/5\n",
      "518/518 [==============================] - 17s 33ms/step - loss: 0.2133 - accuracy: 0.9743\n",
      "Epoch 5/5\n",
      "518/518 [==============================] - 20s 38ms/step - loss: 0.2155 - accuracy: 0.9713\n",
      "130/130 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\eric2\\AppData\\Local\\Temp\\tmp140u0n67\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\eric2\\AppData\\Local\\Temp\\tmp140u0n67\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518/518 [==============================] - 18s 33ms/step - loss: 0.2399 - accuracy: 0.9674\n",
      "Epoch 2/5\n",
      "518/518 [==============================] - 17s 33ms/step - loss: 0.2336 - accuracy: 0.9674\n",
      "Epoch 3/5\n",
      "518/518 [==============================] - 17s 34ms/step - loss: 0.2219 - accuracy: 0.9718\n",
      "Epoch 4/5\n",
      "518/518 [==============================] - 17s 34ms/step - loss: 0.2161 - accuracy: 0.9730\n",
      "Epoch 5/5\n",
      "518/518 [==============================] - 17s 33ms/step - loss: 0.2121 - accuracy: 0.9739\n",
      "130/130 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\eric2\\AppData\\Local\\Temp\\tmpdrqfmav5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\eric2\\AppData\\Local\\Temp\\tmpdrqfmav5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "518/518 [==============================] - 18s 33ms/step - loss: 0.2426 - accuracy: 0.9658\n",
      "Epoch 2/5\n",
      "518/518 [==============================] - 17s 33ms/step - loss: 0.2301 - accuracy: 0.9691\n",
      "Epoch 3/5\n",
      "518/518 [==============================] - 17s 33ms/step - loss: 0.2210 - accuracy: 0.9723\n",
      "Epoch 4/5\n",
      "518/518 [==============================] - 17s 33ms/step - loss: 0.2119 - accuracy: 0.9743\n",
      "Epoch 5/5\n",
      "518/518 [==============================] - 17s 34ms/step - loss: 0.2084 - accuracy: 0.9758\n",
      "130/130 [==============================] - 0s 945us/step\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\eric2\\AppData\\Local\\Temp\\tmpknkfn89p\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\eric2\\AppData\\Local\\Temp\\tmpknkfn89p\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "518/518 [==============================] - 18s 34ms/step - loss: 0.2416 - accuracy: 0.9649\n",
      "Epoch 2/5\n",
      "518/518 [==============================] - 17s 33ms/step - loss: 0.2362 - accuracy: 0.9669\n",
      "Epoch 3/5\n",
      "518/518 [==============================] - 17s 33ms/step - loss: 0.2183 - accuracy: 0.9739\n",
      "Epoch 4/5\n",
      "518/518 [==============================] - 18s 34ms/step - loss: 0.2108 - accuracy: 0.9750\n",
      "Epoch 5/5\n",
      "518/518 [==============================] - 17s 33ms/step - loss: 0.2140 - accuracy: 0.9730\n",
      "130/130 [==============================] - 0s 1ms/step\n",
      "162/162 [==============================] - 0s 904us/step\n",
      "27/27 [==============================] - 0s 997us/step\n",
      "Model Metrics with testing data\n",
      "The accuracy of the Model is 0.8904559505409583\n",
      "The F-Score of the Model is 0.8895946101430124\n",
      "The Recall of the Model is 0.8904559505409583\n",
      "The precision of the Model is 0.8891756693421495\n",
      "The time taken for the Model prediction is 10.612773656845093 seconds\n",
      "The number of records per second is 487.0\n",
      "================================================================\n",
      "Model Metrics with evaluation data\n",
      "The accuracy of the Model is 0.8681710213776722\n",
      "The F-Score of the Model is 0.8613834700506667\n",
      "The Recall of the Model is 0.8681710213776722\n",
      "The precision of the Model is 0.8676691108127645\n",
      "The time taken for the Model prediction is 1.791050672531128 seconds\n",
      "The number of records per second is 470.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "# Start Training with tfidf_vectorizer\n",
    "\n",
    "# Train several other models on your data using different algorithms or hyperparameters\n",
    "lr = LogisticRegression(max_iter = 1000)\n",
    "svm = SVC(kernel = \"rbf\", random_state = 1)\n",
    "nn = KerasClassifier(model= create_model(X_train_vec), epochs=5, batch_size=32)\n",
    "\n",
    "# Use these models to make predictions on your data\n",
    "lr.fit(X_train_vec,y_train)\n",
    "svm.fit(X_train_vec,y_train)\n",
    "nn.fit(X_train_vec,y_train)\n",
    "\n",
    "meta_model = LogisticRegression()\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=[('lr', lr), ('svm', svm), ('nn', nn)],\n",
    "    final_estimator=LogisticRegression()\n",
    ")\n",
    "stacking_model.fit(X_train_vec, y_train)\n",
    "start_time = time.time()\n",
    "y_pred = stacking_model.predict(X_test_vec)\n",
    "end_time = time.time()\n",
    "y_pred = (y_pred >= 0.5).astype(int)\n",
    "time_taken = end_time - start_time\n",
    "\n",
    "\n",
    "start_time_eval = time.time()\n",
    "y_pred_eval = stacking_model.predict(eval_data_x_vec)\n",
    "end_time_eval = time.time()\n",
    "time_taken_eval =  end_time_eval - start_time_eval\n",
    "y_pred_eval = (y_pred_eval >= 0.5).astype(int)\n",
    "\n",
    "metric_report(y_test,y_pred,time_taken,len(y_test), eval_data_y_polarity, y_pred_eval, time_taken_eval, len(eval_data_y_polarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\eric2\\AppData\\Local\\Temp\\tmpprbq3l84\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\eric2\\AppData\\Local\\Temp\\tmpprbq3l84\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "647/647 [==============================] - 23s 35ms/step - loss: 0.5233 - accuracy: 0.7919\n",
      "Epoch 2/5\n",
      "647/647 [==============================] - 20s 30ms/step - loss: 0.3677 - accuracy: 0.8979\n",
      "Epoch 3/5\n",
      "647/647 [==============================] - 18s 28ms/step - loss: 0.3050 - accuracy: 0.9340\n",
      "Epoch 4/5\n",
      "647/647 [==============================] - 18s 28ms/step - loss: 0.2683 - accuracy: 0.9488\n",
      "Epoch 5/5\n",
      "647/647 [==============================] - 19s 30ms/step - loss: 0.2420 - accuracy: 0.9598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\eric2\\AppData\\Local\\Temp\\tmpbz762w0u\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\eric2\\AppData\\Local\\Temp\\tmpbz762w0u\\assets\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\eric2\\AppData\\Local\\Temp\\tmpaht4u77v\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\eric2\\AppData\\Local\\Temp\\tmpaht4u77v\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "518/518 [==============================] - 19s 34ms/step - loss: 0.5454 - accuracy: 0.7727\n",
      "Epoch 2/5\n",
      "518/518 [==============================] - 18s 35ms/step - loss: 0.3949 - accuracy: 0.8910\n",
      "Epoch 3/5\n",
      "518/518 [==============================] - 18s 34ms/step - loss: 0.3190 - accuracy: 0.9323\n",
      "Epoch 4/5\n",
      "518/518 [==============================] - 17s 34ms/step - loss: 0.2766 - accuracy: 0.9520\n",
      "Epoch 5/5\n",
      "518/518 [==============================] - 18s 35ms/step - loss: 0.2524 - accuracy: 0.9611\n",
      "130/130 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\eric2\\AppData\\Local\\Temp\\tmpcc9azf3_\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\eric2\\AppData\\Local\\Temp\\tmpcc9azf3_\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "518/518 [==============================] - 19s 34ms/step - loss: 0.5474 - accuracy: 0.7736\n",
      "Epoch 2/5\n",
      "518/518 [==============================] - 18s 35ms/step - loss: 0.3845 - accuracy: 0.8923\n",
      "Epoch 3/5\n",
      "518/518 [==============================] - 19s 36ms/step - loss: 0.2960 - accuracy: 0.9400\n",
      "Epoch 4/5\n",
      "518/518 [==============================] - 19s 36ms/step - loss: 0.2532 - accuracy: 0.9565\n",
      "Epoch 5/5\n",
      "518/518 [==============================] - 19s 37ms/step - loss: 0.2351 - accuracy: 0.9634\n",
      "130/130 [==============================] - 0s 1ms/step\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\eric2\\AppData\\Local\\Temp\\tmp2e_242mi\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\eric2\\AppData\\Local\\Temp\\tmp2e_242mi\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "518/518 [==============================] - 19s 36ms/step - loss: 0.5476 - accuracy: 0.7725\n",
      "Epoch 2/5\n",
      "518/518 [==============================] - 19s 36ms/step - loss: 0.4233 - accuracy: 0.8884\n",
      "Epoch 3/5\n",
      "518/518 [==============================] - 19s 36ms/step - loss: 0.3522 - accuracy: 0.9265\n",
      "Epoch 4/5\n",
      "518/518 [==============================] - 19s 36ms/step - loss: 0.3120 - accuracy: 0.9408\n",
      "Epoch 5/5\n",
      "518/518 [==============================] - 20s 38ms/step - loss: 0.2881 - accuracy: 0.9469\n",
      "130/130 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\eric2\\AppData\\Local\\Temp\\tmpu298wqiz\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\eric2\\AppData\\Local\\Temp\\tmpu298wqiz\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "518/518 [==============================] - 21s 38ms/step - loss: 0.5511 - accuracy: 0.7726\n",
      "Epoch 2/5\n",
      "518/518 [==============================] - 18s 35ms/step - loss: 0.4146 - accuracy: 0.8920\n",
      "Epoch 3/5\n",
      "518/518 [==============================] - 18s 35ms/step - loss: 0.3513 - accuracy: 0.9268\n",
      "Epoch 4/5\n",
      "518/518 [==============================] - 18s 35ms/step - loss: 0.3146 - accuracy: 0.9422\n",
      "Epoch 5/5\n",
      "518/518 [==============================] - 19s 36ms/step - loss: 0.2911 - accuracy: 0.9477\n",
      "130/130 [==============================] - 0s 978us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\eric2\\AppData\\Local\\Temp\\tmpjnxw0t65\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\eric2\\AppData\\Local\\Temp\\tmpjnxw0t65\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "518/518 [==============================] - 18s 34ms/step - loss: 0.5503 - accuracy: 0.7727\n",
      "Epoch 2/5\n",
      "518/518 [==============================] - 17s 33ms/step - loss: 0.4071 - accuracy: 0.8892\n",
      "Epoch 3/5\n",
      "518/518 [==============================] - 17s 33ms/step - loss: 0.3305 - accuracy: 0.9279\n",
      "Epoch 4/5\n",
      "518/518 [==============================] - 17s 33ms/step - loss: 0.2916 - accuracy: 0.9456\n",
      "Epoch 5/5\n",
      "518/518 [==============================] - 17s 33ms/step - loss: 0.2607 - accuracy: 0.9588\n",
      "130/130 [==============================] - 0s 930us/step\n",
      "162/162 [==============================] - 0s 969us/step\n",
      "27/27 [==============================] - 0s 1ms/step\n",
      "Model Metrics with testing data\n",
      "The accuracy of the Model is 0.892774343122102\n",
      "The F-Score of the Model is 0.8924357089269304\n",
      "The Recall of the Model is 0.892774343122102\n",
      "The precision of the Model is 0.8921718085861989\n",
      "The time taken for the Model prediction is 11.44518256187439 seconds\n",
      "The number of records per second is 452.0\n",
      "================================================================\n",
      "Model Metrics with evaluation data\n",
      "The accuracy of the Model is 0.8741092636579573\n",
      "The F-Score of the Model is 0.8680090922400242\n",
      "The Recall of the Model is 0.8741092636579573\n",
      "The precision of the Model is 0.8738090154527742\n",
      "The time taken for the Model prediction is 1.920206069946289 seconds\n",
      "The number of records per second is 438.0\n"
     ]
    }
   ],
   "source": [
    "# Start Training with tfidf_vectorizer\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# Train several other models on your data using different algorithms or hyperparameters\n",
    "lr = LogisticRegression(max_iter = 1000)\n",
    "svm = SVC(kernel = \"rbf\", random_state = 1)\n",
    "nn = KerasClassifier(model= create_model(X_train_tfidf) , epochs=5, batch_size=32)\n",
    "\n",
    "\n",
    "meta_model = LogisticRegression()\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=[('lr', lr), ('svm', svm), ('nn', nn)],\n",
    "    final_estimator=LogisticRegression()\n",
    ")\n",
    "\n",
    "stacking_model.fit(X_train_tfidf, y_train)\n",
    "start_time = time.time()\n",
    "y_pred = stacking_model.predict(X_test_tfidf)\n",
    "end_time = time.time()\n",
    "y_pred = (y_pred >= 0.5).astype(int)\n",
    "time_taken = end_time - start_time\n",
    "\n",
    "\n",
    "start_time_eval = time.time()\n",
    "y_pred_eval = stacking_model.predict(eval_data_x_tfidf)\n",
    "end_time_eval = time.time()\n",
    "time_taken_eval =  end_time_eval - start_time_eval\n",
    "y_pred_eval = (y_pred_eval >= 0.5).astype(int)\n",
    "\n",
    "metric_report(y_test,y_pred,time_taken,len(y_test), eval_data_y_polarity, y_pred_eval, time_taken_eval, len(eval_data_y_polarity))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Metrics with testing data\n",
      "The accuracy of the Model is 0.8887171561051005\n",
      "The F-Score of the Model is 0.8860434138335391\n",
      "The Recall of the Model is 0.8887171561051005\n",
      "The precision of the Model is 0.8870148190622066\n",
      "The time taken for the Model prediction is 10.120749235153198 seconds\n",
      "The number of records per second is 511.0\n",
      "================================================================\n",
      "Model Metrics with evaluation data\n",
      "The accuracy of the Model is 0.8551068883610451\n",
      "The F-Score of the Model is 0.8446343086790544\n",
      "The Recall of the Model is 0.8551068883610451\n",
      "The precision of the Model is 0.857101661891036\n",
      "The time taken for the Model prediction is 1.5841286182403564 seconds\n",
      "The number of records per second is 531.0\n"
     ]
    }
   ],
   "source": [
    "#Ensemble Classifier for Vectorised \n",
    "clf1 = LogisticRegression(max_iter = 1000)\n",
    "clf2 = MLPClassifier(solver = \"adam\", alpha = 1e-5, \n",
    "                   hidden_layer_sizes =(64,2), activation = 'tanh',  max_iter = 1000, early_stopping = True)\n",
    "clf3 = SVC(kernel = \"rbf\", random_state = 1)\n",
    "\n",
    "# Create the ensemble classifier\n",
    "ensemble = VotingClassifier(estimators=[('lr', clf1), ('nn', clf2), ('svc', clf3)], voting='hard')\n",
    "\n",
    "# Train the ensemble classifier\n",
    "ensemble.fit(X_train_vec,y_train)\n",
    "start_time = time.time()\n",
    "# Make predictions on the test set\n",
    "y_pred = ensemble.predict(X_test_vec)\n",
    "end_time = time.time()\n",
    "time_taken =  end_time - start_time\n",
    "y_pred = (y_pred >= 0.5).astype(int)\n",
    "\n",
    "start_time_eval = time.time()\n",
    "y_pred_eval = ensemble.predict(eval_data_x_vec)\n",
    "end_time_eval = time.time()\n",
    "time_taken_eval =  end_time_eval - start_time_eval\n",
    "y_pred_eval = (y_pred_eval >= 0.5).astype(int)\n",
    "\n",
    "\n",
    "# Rounding off time to the nearest 0.00001s to avoid values to 0.\n",
    "if time_taken <= 0.00001:\n",
    "    time_taken = 0.00001\n",
    "    \n",
    "if time_taken_eval <= 0.00001:\n",
    "    time_taken_eval = 0.00001\n",
    "# Evaluate the model using accuracy score\n",
    "\n",
    "metric_report(y_test,y_pred,time_taken,len(y_test), eval_data_y_polarity, y_pred_eval, time_taken_eval, len(eval_data_y_polarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Metrics with testing data\n",
      "The accuracy of the Model is 0.8736476043276662\n",
      "The F-Score of the Model is 0.8672763540467812\n",
      "The Recall of the Model is 0.8736476043276662\n",
      "The precision of the Model is 0.8743353709339633\n",
      "The time taken for the Model prediction is 10.031439065933228 seconds\n",
      "The number of records per second is 515.0\n",
      "================================================================\n",
      "Model Metrics with evaluation data\n",
      "The accuracy of the Model is 0.8479809976247031\n",
      "The F-Score of the Model is 0.8331694307034736\n",
      "The Recall of the Model is 0.8479809976247031\n",
      "The precision of the Model is 0.8561338846534287\n",
      "The time taken for the Model prediction is 1.6260128021240234 seconds\n",
      "The number of records per second is 517.0\n"
     ]
    }
   ],
   "source": [
    "#Ensemble Classifier for tfidf\n",
    "clf1 = LogisticRegression(max_iter = 1000)\n",
    "clf2 = MLPClassifier(solver = \"adam\", alpha = 1e-5, \n",
    "                   hidden_layer_sizes =(64,2), activation = 'tanh',  max_iter = 1000, early_stopping = True)\n",
    "clf3 = SVC(kernel = \"rbf\", random_state = 1)\n",
    "\n",
    "# Create the ensemble classifier\n",
    "ensemble = VotingClassifier(estimators=[('lr', clf1), ('nn', clf2), ('svc', clf3)], voting='hard')\n",
    "\n",
    "# Train the ensemble classifier\n",
    "ensemble.fit(X_train_tfidf,y_train)\n",
    "start_time = time.time()\n",
    "# Make predictions on the test set\n",
    "y_pred = ensemble.predict(X_test_tfidf)\n",
    "end_time = time.time()\n",
    "time_taken =  end_time - start_time\n",
    "y_pred = (y_pred >= 0.5).astype(int)\n",
    "\n",
    "start_time_eval = time.time()\n",
    "y_pred_eval = ensemble.predict(eval_data_x_tfidf)\n",
    "end_time_eval = time.time()\n",
    "time_taken_eval =  end_time_eval - start_time_eval\n",
    "y_pred_eval = (y_pred_eval >= 0.5).astype(int)\n",
    "\n",
    "\n",
    "# Rounding off time to the nearest 0.00001s to avoid values to 0.\n",
    "if time_taken <= 0.00001:\n",
    "    time_taken = 0.00001\n",
    "    \n",
    "if time_taken_eval <= 0.00001:\n",
    "    time_taken_eval = 0.00001\n",
    "# Evaluate the model using accuracy score\n",
    "\n",
    "metric_report(y_test,y_pred,time_taken,len(y_test), eval_data_y_polarity, y_pred_eval, time_taken_eval, len(eval_data_y_polarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\eric2\\AppData\\Local\\Temp\\tmprbfwlqkm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\eric2\\AppData\\Local\\Temp\\tmprbfwlqkm\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "647/647 [==============================] - 22s 34ms/step - loss: 0.5273 - accuracy: 0.7969\n",
      "Epoch 2/5\n",
      "647/647 [==============================] - 21s 33ms/step - loss: 0.3747 - accuracy: 0.9030\n",
      "Epoch 3/5\n",
      "647/647 [==============================] - 21s 33ms/step - loss: 0.3075 - accuracy: 0.9398\n",
      "Epoch 4/5\n",
      "647/647 [==============================] - 21s 33ms/step - loss: 0.2751 - accuracy: 0.9545\n",
      "Epoch 5/5\n",
      "647/647 [==============================] - 23s 35ms/step - loss: 0.2543 - accuracy: 0.9618\n",
      "162/162 [==============================] - 0s 980us/step\n",
      "27/27 [==============================] - 0s 894us/step\n",
      "Model Metrics with testing data\n",
      "The accuracy of the Model is 0.8763523956723338\n",
      "The F-Score of the Model is 0.8701175330121406\n",
      "The Recall of the Model is 0.8763523956723338\n",
      "The precision of the Model is 0.8773925137820683\n",
      "The time taken for the Model prediction is 11.41761827468872 seconds\n",
      "The number of records per second is 453.0\n",
      "================================================================\n",
      "Model Metrics with evaluation data\n",
      "The accuracy of the Model is 0.8467933491686461\n",
      "The F-Score of the Model is 0.8316585674153436\n",
      "The Recall of the Model is 0.8467933491686461\n",
      "The precision of the Model is 0.8550843909184495\n",
      "The time taken for the Model prediction is 1.864170789718628 seconds\n",
      "The number of records per second is 451.0\n"
     ]
    }
   ],
   "source": [
    "#Ensemble Classifier for tfidf\n",
    "clf1 = LogisticRegression(max_iter = 1000)\n",
    "clf2 = KerasClassifier(model= create_model(X_train_tfidf), epochs=5, batch_size=32)\n",
    "clf3 = SVC(kernel = \"rbf\", random_state = 1)\n",
    "\n",
    "# Create the ensemble classifier\n",
    "ensemble = VotingClassifier(estimators=[('lr', clf1), ('keras', clf2), ('svc', clf3)], voting='hard')\n",
    "\n",
    "# Train the ensemble classifier\n",
    "ensemble.fit(X_train_tfidf,y_train)\n",
    "start_time = time.time()\n",
    "# Make predictions on the test set\n",
    "y_pred = ensemble.predict(X_test_tfidf)\n",
    "end_time = time.time()\n",
    "time_taken =  end_time - start_time\n",
    "y_pred = (y_pred >= 0.5).astype(int)\n",
    "\n",
    "start_time_eval = time.time()\n",
    "y_pred_eval = ensemble.predict(eval_data_x_tfidf)\n",
    "end_time_eval = time.time()\n",
    "time_taken_eval =  end_time_eval - start_time_eval\n",
    "y_pred_eval = (y_pred_eval >= 0.5).astype(int)\n",
    "\n",
    "\n",
    "# Rounding off time to the nearest 0.00001s to avoid values to 0.\n",
    "if time_taken <= 0.00001:\n",
    "    time_taken = 0.00001\n",
    "    \n",
    "if time_taken_eval <= 0.00001:\n",
    "    time_taken_eval = 0.00001\n",
    "# Evaluate the model using accuracy score\n",
    "\n",
    "metric_report(y_test,y_pred,time_taken,len(y_test), eval_data_y_polarity, y_pred_eval, time_taken_eval, len(eval_data_y_polarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\eric2\\AppData\\Local\\Temp\\tmpeam_zn2m\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\eric2\\AppData\\Local\\Temp\\tmpeam_zn2m\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "647/647 [==============================] - 22s 31ms/step - loss: 0.5405 - accuracy: 0.7952\n",
      "Epoch 2/5\n",
      "647/647 [==============================] - 19s 29ms/step - loss: 0.3820 - accuracy: 0.9059\n",
      "Epoch 3/5\n",
      "647/647 [==============================] - 19s 30ms/step - loss: 0.3083 - accuracy: 0.9400\n",
      "Epoch 4/5\n",
      "647/647 [==============================] - 19s 30ms/step - loss: 0.2760 - accuracy: 0.9539\n",
      "Epoch 5/5\n",
      "647/647 [==============================] - 20s 30ms/step - loss: 0.2558 - accuracy: 0.9611\n",
      "162/162 [==============================] - 0s 970us/step\n",
      "27/27 [==============================] - 0s 959us/step\n",
      "Model Metrics with testing data\n",
      "The accuracy of the Model is 0.8887171561051005\n",
      "The F-Score of the Model is 0.8855717876765451\n",
      "The Recall of the Model is 0.8887171561051005\n",
      "The precision of the Model is 0.8873352774583042\n",
      "The time taken for the Model prediction is 9.863991260528564 seconds\n",
      "The number of records per second is 524.0\n",
      "================================================================\n",
      "Model Metrics with evaluation data\n",
      "The accuracy of the Model is 0.8622327790973872\n",
      "The F-Score of the Model is 0.8525953833193325\n",
      "The Recall of the Model is 0.8622327790973872\n",
      "The precision of the Model is 0.8650214539827323\n",
      "The time taken for the Model prediction is 1.6101984977722168 seconds\n",
      "The number of records per second is 522.0\n"
     ]
    }
   ],
   "source": [
    "#Ensemble Classifier for vec\n",
    "clf1 = LogisticRegression(max_iter = 1000)\n",
    "clf2 = KerasClassifier(model= create_model(X_train_vec), epochs=5, batch_size=32)\n",
    "clf3 = SVC(kernel = \"rbf\", random_state = 1)\n",
    "\n",
    "# Create the ensemble classifier\n",
    "ensemble = VotingClassifier(estimators=[('lr', clf1), ('tf', clf2), ('svc', clf3)], voting='hard')\n",
    "\n",
    "# Train the ensemble classifier\n",
    "ensemble.fit(X_train_vec,y_train)\n",
    "start_time = time.time()\n",
    "# Make predictions on the test set\n",
    "y_pred = ensemble.predict(X_test_vec)\n",
    "end_time = time.time()\n",
    "time_taken =  end_time - start_time\n",
    "y_pred = (y_pred >= 0.5).astype(int)\n",
    "\n",
    "start_time_eval = time.time()\n",
    "y_pred_eval = ensemble.predict(eval_data_x_vec)\n",
    "end_time_eval = time.time()\n",
    "time_taken_eval =  end_time_eval - start_time_eval\n",
    "y_pred_eval = (y_pred_eval >= 0.5).astype(int)\n",
    "\n",
    "# Rounding off time to the nearest 0.00001s to avoid values to 0.\n",
    "if time_taken <= 0.00001:\n",
    "    time_taken = 0.00001\n",
    "    \n",
    "if time_taken_eval <= 0.00001:\n",
    "    time_taken_eval = 0.00001\n",
    "# Evaluate the model using accuracy score\n",
    "\n",
    "metric_report(y_test,y_pred,time_taken,len(y_test), eval_data_y_polarity, y_pred_eval, time_taken_eval, len(eval_data_y_polarity))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Average Ensemble Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Weights for the Classifiers\n",
    "\n",
    "lr_weight = 0.2\n",
    "svm_weight = 0.5\n",
    "nn_weight = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Metrics with testing data\n",
      "The accuracy of the Model is 0.8717156105100463\n",
      "The F-Score of the Model is 0.864658740750019\n",
      "The Recall of the Model is 0.8717156105100463\n",
      "The precision of the Model is 0.8731860870827328\n",
      "The time taken for the Model prediction is 13.628058195114136 seconds\n",
      "The number of records per second is 379.0\n",
      "================================================================\n",
      "Model Metrics with evaluation data\n",
      "The accuracy of the Model is 0.8467933491686461\n",
      "The F-Score of the Model is 0.8320720899890943\n",
      "The Recall of the Model is 0.8467933491686461\n",
      "The precision of the Model is 0.854102148956951\n",
      "The time taken for the Model prediction is 1.9108002185821533 seconds\n",
      "The number of records per second is 440.0\n"
     ]
    }
   ],
   "source": [
    "# Weighted Average Ensemble Classification (TFIDF) for Logistic Regression/SVC/MLP\n",
    "\n",
    "# Train several other models on your data using different algorithms or hyperparameters\n",
    "lr = LogisticRegression(max_iter = 1000)\n",
    "svm = SVC(kernel = \"rbf\", random_state = 1)\n",
    "nn = MLPClassifier(solver = \"adam\", alpha = 1e-5, \n",
    "                    hidden_layer_sizes =(64,2), activation = 'tanh',  max_iter = 1000, early_stopping = True)\n",
    "\n",
    "# Use these models to make predictions on your data\n",
    "lr.fit(X_train_tfidf,y_train)\n",
    "svm.fit(X_train_tfidf,y_train)\n",
    "nn.fit(X_train_tfidf,y_train)\n",
    "\n",
    "start_time = time.time()\n",
    "lr_pred = lr.predict(X_test_tfidf)\n",
    "svm_pred = svm.predict(X_test_tfidf)\n",
    "nn_pred = nn.predict(X_test_tfidf)\n",
    "\n",
    "y_pred = (nn_weight*nn_pred) + (svm_weight*svm_pred) + (lr_weight*lr_pred)\n",
    "end_time = time.time()\n",
    "time_taken = end_time - start_time\n",
    "y_pred = (y_pred >= 0.5).astype(int)\n",
    "\n",
    "start_time_eval = time.time()\n",
    "lr_pred_eval = lr.predict(eval_data_x_tfidf)\n",
    "svm_pred_eval = svm.predict(eval_data_x_tfidf)\n",
    "nn_pred_eval = nn.predict(eval_data_x_tfidf)\n",
    "\n",
    "y_pred_eval = (nn_weight*nn_pred_eval) + (svm_weight*svm_pred_eval) + (lr_weight*lr_pred_eval)\n",
    "end_time_eval = time.time()\n",
    "time_taken_eval = end_time_eval - start_time_eval\n",
    "y_pred_eval = (y_pred_eval >= 0.5).astype(int)\n",
    "\n",
    "metric_report(y_test,y_pred,time_taken,len(y_test), eval_data_y_polarity, y_pred_eval, time_taken_eval, len(eval_data_y_polarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Metrics with testing data\n",
      "The accuracy of the Model is 0.8693972179289027\n",
      "The F-Score of the Model is 0.8616390814745114\n",
      "The Recall of the Model is 0.8693972179289027\n",
      "The precision of the Model is 0.8716164145134563\n",
      "The time taken for the Model prediction is 12.20228385925293 seconds\n",
      "The number of records per second is 424.0\n",
      "================================================================\n",
      "Model Metrics with evaluation data\n",
      "The accuracy of the Model is 0.8432304038004751\n",
      "The F-Score of the Model is 0.8270974973932708\n",
      "The Recall of the Model is 0.8432304038004751\n",
      "The precision of the Model is 0.8519320703606944\n",
      "The time taken for the Model prediction is 2.3207924365997314 seconds\n",
      "The number of records per second is 362.0\n"
     ]
    }
   ],
   "source": [
    "# Weighted Average Ensemble Classification (CountVectorizer) for Logistic Regression/SVC/MLP\n",
    "\n",
    "# Train several other models on your data using different algorithms or hyperparameters\n",
    "lr = LogisticRegression(max_iter = 1000)\n",
    "svm = SVC(kernel = \"rbf\", random_state = 1)\n",
    "nn = MLPClassifier(solver = \"adam\", alpha = 1e-5, \n",
    "                    hidden_layer_sizes =(64,2), activation = 'tanh',  max_iter = 1000, early_stopping = True)\n",
    "\n",
    "# Use these models to make predictions on your data\n",
    "lr.fit(X_train_vec,y_train)\n",
    "svm.fit(X_train_vec,y_train)\n",
    "nn.fit(X_train_vec,y_train)\n",
    "\n",
    "start_time = time.time()\n",
    "lr_pred = lr.predict(X_test_vec)\n",
    "svm_pred = svm.predict(X_test_vec)\n",
    "nn_pred = nn.predict(X_test_vec)\n",
    "\n",
    "y_pred = (nn_weight*nn_pred) + (svm_weight*svm_pred) + (lr_weight*lr_pred)\n",
    "end_time = time.time()\n",
    "time_taken = end_time - start_time\n",
    "y_pred = (y_pred >= 0.5).astype(int)\n",
    "\n",
    "start_time_eval = time.time()\n",
    "lr_pred_eval = lr.predict(eval_data_x_vec)\n",
    "svm_pred_eval = svm.predict(eval_data_x_vec)\n",
    "nn_pred_eval = nn.predict(eval_data_x_vec)\n",
    "\n",
    "y_pred_eval = (nn_weight*nn_pred_eval) + (svm_weight*svm_pred_eval) + (lr_weight*lr_pred_eval)\n",
    "end_time_eval = time.time()\n",
    "time_taken_eval = end_time_eval - start_time_eval\n",
    "y_pred_eval = (y_pred_eval >= 0.5).astype(int)\n",
    "\n",
    "metric_report(y_test,y_pred,time_taken,len(y_test), eval_data_y_polarity, y_pred_eval, time_taken_eval, len(eval_data_y_polarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "647/647 [==============================] - 23s 34ms/step - loss: 0.5459 - accuracy: 0.7953\n",
      "162/162 [==============================] - 0s 1ms/step\n",
      "27/27 [==============================] - 0s 882us/step\n",
      "Model Metrics with testing data\n",
      "The accuracy of the Model is 0.8684312210200927\n",
      "The F-Score of the Model is 0.8607282058985348\n",
      "The Recall of the Model is 0.8684312210200927\n",
      "The precision of the Model is 0.8702784899319054\n",
      "The time taken for the Model prediction is 9.970266819000244 seconds\n",
      "The number of records per second is 519.0\n",
      "================================================================\n",
      "Model Metrics with evaluation data\n",
      "The accuracy of the Model is 0.8456057007125891\n",
      "The F-Score of the Model is 0.8305627030582153\n",
      "The Recall of the Model is 0.8456057007125891\n",
      "The precision of the Model is 0.8530394380034049\n",
      "The time taken for the Model prediction is 1.7275280952453613 seconds\n",
      "The number of records per second is 487.0\n"
     ]
    }
   ],
   "source": [
    "# Weighted Average Ensemble Classification (CountVectorizer) for Logistic Regression/SVC/TF-FFN\n",
    "# Train several other models on your data using different algorithms or hyperparameters\n",
    "lr = LogisticRegression(max_iter = 1000)\n",
    "svm = SVC(kernel = \"rbf\", random_state = 1)\n",
    "nn = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape = (X_train_vec.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-5, l2=1e-4)),\n",
    "    tf.keras.layers.Dropout(rate=0.5),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-5, l2=1e-4)),\n",
    "    tf.keras.layers.Dropout(rate=0.5),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-5, l2=1e-4)),\n",
    "    tf.keras.layers.Dropout(rate=0.5),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-5, l2=1e-4)),\n",
    "    tf.keras.layers.Dropout(rate=0.5),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# Compile the model_tfidf\n",
    "nn.compile(loss=loss, optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "\n",
    "# Use these models to make predictions on your data\n",
    "lr.fit(X_train_vec,y_train)\n",
    "svm.fit(X_train_vec,y_train)\n",
    "nn.fit(X_train_vec,y_train, epochs = 1)\n",
    "\n",
    "start_time = time.time()\n",
    "lr_pred = np.array(lr.predict(X_test_vec))\n",
    "svm_pred = np.array(svm.predict(X_test_vec))\n",
    "nn_pred = np.array(nn.predict(X_test_vec))\n",
    "nn_pred = (nn_pred >= 0.5).astype(int)\n",
    "nn_pred = nn_pred.ravel()\n",
    "\n",
    "y_pred= (nn_weight*nn_pred) + (svm_weight*svm_pred) + (lr_weight*lr_pred)\n",
    "end_time = time.time()\n",
    "time_taken = end_time - start_time\n",
    "y_pred = (y_pred >= 0.5).astype(int)\n",
    "\n",
    "y_pred = y_pred.ravel()\n",
    "\n",
    "start_time_eval = time.time()\n",
    "lr_pred_eval = np.array(lr.predict(eval_data_x_vec))\n",
    "svm_pred_eval = np.array(svm.predict(eval_data_x_vec))\n",
    "nn_pred_eval = np.array(nn.predict(eval_data_x_vec))\n",
    "nn_pred_eval = nn_pred_eval.ravel()\n",
    "\n",
    "y_pred_eval = nn_weight*nn_pred_eval+ svm_weight*svm_pred_eval + lr_weight*lr_pred_eval\n",
    "end_time_eval = time.time()\n",
    "time_taken_eval = end_time_eval - start_time_eval\n",
    "y_pred_eval = (y_pred_eval >= 0.5).astype(int)\n",
    "y_pred_eval = y_pred_eval.ravel()\n",
    "\n",
    "metric_report(y_test,y_pred,time_taken,len(y_test), eval_data_y_polarity, y_pred_eval, time_taken_eval, len(eval_data_y_polarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "647/647 [==============================] - 19s 28ms/step - loss: 0.5369 - accuracy: 0.7957\n",
      "162/162 [==============================] - 0s 787us/step\n",
      "27/27 [==============================] - 0s 882us/step\n",
      "Model Metrics with testing data\n",
      "The accuracy of the Model is 0.8695904173106646\n",
      "The F-Score of the Model is 0.8619107424042407\n",
      "The Recall of the Model is 0.8695904173106646\n",
      "The precision of the Model is 0.8717069613965021\n",
      "The time taken for the Model prediction is 10.577749013900757 seconds\n",
      "The number of records per second is 489.0\n",
      "================================================================\n",
      "Model Metrics with evaluation data\n",
      "The accuracy of the Model is 0.8479809976247031\n",
      "The F-Score of the Model is 0.8339784532507322\n",
      "The Recall of the Model is 0.8479809976247031\n",
      "The precision of the Model is 0.854245758640058\n",
      "The time taken for the Model prediction is 1.6730055809020996 seconds\n",
      "The number of records per second is 503.0\n"
     ]
    }
   ],
   "source": [
    "# Weighted Average Ensemble Classification (TFIDF) for Logistic Regression/SVC/TF-FFN\n",
    "# Train several other models on your data using different algorithms or hyperparameters\n",
    "lr = LogisticRegression(max_iter = 1000)\n",
    "svm = SVC(kernel = \"rbf\", random_state = 1)\n",
    "nn = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape = (X_train_tfidf.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-5, l2=1e-4)),\n",
    "    tf.keras.layers.Dropout(rate=0.5),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-5, l2=1e-4)),\n",
    "    tf.keras.layers.Dropout(rate=0.5),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-5, l2=1e-4)),\n",
    "    tf.keras.layers.Dropout(rate=0.5),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-5, l2=1e-4)),\n",
    "    tf.keras.layers.Dropout(rate=0.5),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# Compile the model_tfidf\n",
    "nn.compile(loss=loss, optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "\n",
    "# Use these models to make predictions on your data\n",
    "lr.fit(X_train_tfidf,y_train)\n",
    "svm.fit(X_train_tfidf,y_train)\n",
    "nn.fit(X_train_tfidf,y_train)\n",
    "\n",
    "start_time = time.time()\n",
    "lr_pred = lr.predict(X_test_tfidf)\n",
    "svm_pred = svm.predict(X_test_tfidf)\n",
    "nn_pred = nn.predict(X_test_tfidf)\n",
    "nn_pred = (nn_pred >= 0.5).astype(int)\n",
    "nn_pred = nn_pred.ravel()\n",
    "\n",
    "y_pred = (nn_weight*nn_pred) + (svm_weight*svm_pred) + (lr_weight*lr_pred)\n",
    "end_time = time.time()\n",
    "time_taken = end_time - start_time\n",
    "y_pred = (y_pred >= 0.5).astype(int)\n",
    "y_pred = y_pred.ravel()\n",
    "\n",
    "start_time_eval = time.time()\n",
    "lr_pred_eval = lr.predict(eval_data_x_tfidf)\n",
    "svm_pred_eval = svm.predict(eval_data_x_tfidf)\n",
    "nn_pred_eval = nn.predict(eval_data_x_tfidf)\n",
    "nn_pred_eval = nn_pred_eval.ravel()\n",
    "\n",
    "y_pred_eval = (nn_weight*nn_pred_eval) + (svm_weight*svm_pred_eval) + (lr_weight*lr_pred_eval)\n",
    "end_time_eval = time.time()\n",
    "time_taken_eval = end_time_eval - start_time_eval\n",
    "y_pred_eval = (y_pred_eval >= 0.5).astype(int)\n",
    "y_pred_eval = y_pred_eval.ravel()\n",
    "\n",
    "metric_report(y_test,y_pred,time_taken,len(y_test), eval_data_y_polarity, y_pred_eval, time_taken_eval, len(eval_data_y_polarity))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e4bda67f9838be16d189b50da62d733f7c09545de52b735a31e173c43804dd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
